{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.append(\"D:/DST/\")\n",
    "import cathay_db as db\n",
    "import utils as ut\n",
    "import financial_statement as fs\n",
    "\n",
    "reload(ut)\n",
    "reload(fs)\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "from toolbox import print_progress_bar\n",
    "\n",
    "# set max display rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# set max display columns\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# Set the float format to display without scientific notation\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read data from feather file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # following is data from tej\n",
    "# df_adjusted_price = pd.read_feather('data/tej_adjusted_price.feather')\n",
    "\n",
    "# # following is data from cmoney\n",
    "# df_price = pd.read_feather('data/cmoney_price.feather')\n",
    "# df_company_info = pd.read_feather('data/cmoney_company_info.feather')\n",
    "\n",
    "# ticker_list = np.sort(pd.unique(df_company_info['股票代號']))\n",
    "\n",
    "# df_price = ut.cmoney_data_clean_up(df_price)\n",
    "# df_price = deepcopy(df_price[df_price['股票代號'].isin(ticker_list)])\n",
    "\n",
    "# df_adjusted_price = ut.tej_data_clean_up(df_adjusted_price)\n",
    "# df_adjusted_price = deepcopy(df_adjusted_price[df_adjusted_price['股票代號'].isin(ticker_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all = pd.read_feather('data/df_factor_all.feather')\n",
    "df_factor_all = df_factor_all[df_factor_all['date'] >= '2004-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all.sort_values(['ticker', 'date'], inplace=True)\n",
    "df_factor_all['y'] = df_factor_all.groupby('ticker', as_index=False, group_keys=False)['price'].pct_change(-62)\n",
    "# group by date and ticker and normalize the y\n",
    "df_factor_all['norm_y'] = df_factor_all.groupby('date', as_index=False, group_keys=False)['y'].apply(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# replace inf with 9999\n",
    "df_factor_all.replace([np.inf], 9999, inplace=True)\n",
    "df_factor_all.replace([-np.inf], -9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebalance_date(date_list, start_date, end_date, freq='Q'):\n",
    "    next_four_seasons = [start_date]\n",
    "    rebalance_date = start_date\n",
    "    i = 0\n",
    "    while rebalance_date < end_date:\n",
    "        if freq == 'Q':\n",
    "            rebalance_date = start_date + pd.DateOffset(months=3 * (i + 1))\n",
    "        elif freq == 'M':\n",
    "            rebalance_date = start_date + pd.DateOffset(months=1 * (i + 1))\n",
    "        elif freq == 'Y':\n",
    "            rebalance_date = start_date + pd.DateOffset(years=1 * (i + 1))\n",
    "\n",
    "        # check if rebalance_date is in date_list\n",
    "        if rebalance_date in date_list:\n",
    "            next_four_seasons.append(rebalance_date)\n",
    "        else:\n",
    "            # if not, find the next date in date_list\n",
    "            for date in date_list:\n",
    "                if date > rebalance_date:\n",
    "                    # chang np.datetime64 to pd.Timestamp\n",
    "                    rebalance_date = pd.Timestamp(date)\n",
    "                    next_four_seasons.append(rebalance_date)\n",
    "                    break\n",
    "        i += 1\n",
    "    return next_four_seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = np.sort(pd.unique(df_factor_all['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_date_lst = get_rebalance_date(date_list, pd.to_datetime('2004-03-15'), pd.to_datetime('2023-3-15'), freq='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asset_qoq', 'asset_yoy', 'ni_qoq', 'ni_yoy', 'roe', 'roe_yoy', 'roe_4q_sum', 'roe_4q_sum_yoy', 'tobins_q', 'ocf / asset', '20_d_return', '40_d_return', '60_d_return', 'dividend_1Y_sum_yield', 'dividend_2Y_sum_yield', 'dividend_3Y_sum_yield', 'last_dividend_yield']\n"
     ]
    }
   ],
   "source": [
    "factor_columns = df_factor_all.columns.tolist()\n",
    "factor_columns.remove('date')\n",
    "factor_columns.remove('ticker')\n",
    "factor_columns.remove('price')\n",
    "factor_columns.remove('y')\n",
    "factor_columns.remove('norm_y')\n",
    "factor_columns.remove('ppe_qoq')\n",
    "factor_columns.remove('ppe_yoy')\n",
    "factor_columns.remove('excess_return')\n",
    "print(factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['norm_y']\n",
    "df_factor_all = df_factor_all.dropna(subset=factor_columns + target_cols, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rebalance_date_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-03-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "start_index = 4\n",
    "\n",
    "print(rebalance_date_lst[start_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |--------------------------------------------------| 0.0% Complete\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "# name the folder by current date and time\n",
    "folder_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "model_save_path = f'D:/Projects/0_HIDIV/models/{folder_name}'\n",
    "\n",
    "# create a folder to save model\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "\n",
    "\n",
    "total = len(rebalance_date_lst) - start_index  # Total number of iterations\n",
    "\n",
    "print_progress_bar(0, total, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "for i in range(start_index, len(rebalance_date_lst)):\n",
    "    # expanding window\n",
    "    train_date = rebalance_date_lst[0:i]\n",
    "    rebalance_date = rebalance_date_lst[i]\n",
    "\n",
    "    # data valid date = rebalance_date - 62 days\n",
    "    data_valid_date = rebalance_date - pd.DateOffset(days=62)\n",
    "\n",
    "    # remove date in train_date if date > data_valid_date\n",
    "    valid_train_date = [date for date in train_date if date <= data_valid_date]\n",
    "\n",
    "    # 訓練股票\n",
    "    param_search = dict(\n",
    "        learning_rate=[0.01, 0.05, 0.1],\n",
    "        max_depth=[3, 5, 7],\n",
    "        n_estimators=[5, 10, 50, 100, 200],\n",
    "    )\n",
    "\n",
    "    df_factor_all_train = df_factor_all[df_factor_all['date'].isin(train_date)]\n",
    "    \n",
    "    model_stock = XGBRegressor()\n",
    "    gscv = GridSearchCV(\n",
    "        model_stock, param_search, refit=True, scoring=\"neg_root_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    gscv.fit(df_factor_all_train[factor_columns], df_factor_all_train[target_cols])\n",
    "    # timestamp to string format for saving model\n",
    "    rebalance_date = rebalance_date.strftime(\"%Y%m%d\")\n",
    "    gscv.best_estimator_.save_model(f\"{model_save_path}/{rebalance_date}.json\")\n",
    "\n",
    "    # Update Progress Bar\n",
    "    print_progress_bar(i-start_index+1, total, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "print_progress_bar(total, total, prefix = 'Progress:', suffix = 'Complete', length = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a data/{folder_name} if not exist\n",
    "if not os.path.exists(f'data/model/{folder_name}'):\n",
    "    os.makedirs(f'data/model/{folder_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string the rebalance_date_lst for saving json\n",
    "rebalance_date_lst_str = [date.strftime(\"%Y%m%d\") for date in rebalance_date_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the setting as a json file\n",
    "with open(f'data/model/{folder_name}/setting.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'start_index': start_index,\n",
    "        'rebalance_date_lst': rebalance_date_lst_str,\n",
    "        'factor_columns': factor_columns,\n",
    "        'target_cols': target_cols,\n",
    "        'model_save_path': model_save_path,\n",
    "        # also the param_search\n",
    "        'param_search': param_search\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_index for df_factor_all\n",
    "df_factor_all = df_factor_all.reset_index(drop=True)\n",
    "\n",
    "# save the df_factor_all as a feather file\n",
    "df_factor_all.to_feather(f'data/model/{folder_name}/df_factor_all.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
