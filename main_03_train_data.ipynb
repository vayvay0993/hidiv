{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.append(\"D:/DST/\")\n",
    "import cathay_db as db\n",
    "import utils as ut\n",
    "import financial_statement as fs\n",
    "\n",
    "reload(ut)\n",
    "reload(fs)\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "from toolbox import print_progress_bar\n",
    "\n",
    "# set max display rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# set max display columns\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# Set the float format to display without scientific notation\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read data from feather file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # following is data from tej\n",
    "# df_adjusted_price = pd.read_feather('data/tej_adjusted_price.feather')\n",
    "\n",
    "# # following is data from cmoney\n",
    "# df_price = pd.read_feather('data/cmoney_price.feather')\n",
    "# df_company_info = pd.read_feather('data/cmoney_company_info.feather')\n",
    "\n",
    "# ticker_list = np.sort(pd.unique(df_company_info['股票代號']))\n",
    "\n",
    "# df_price = ut.cmoney_data_clean_up(df_price)\n",
    "# df_price = deepcopy(df_price[df_price['股票代號'].isin(ticker_list)])\n",
    "\n",
    "# df_adjusted_price = ut.tej_data_clean_up(df_adjusted_price)\n",
    "# df_adjusted_price = deepcopy(df_adjusted_price[df_adjusted_price['股票代號'].isin(ticker_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all = pd.read_feather('data/df_factor_all.feather')\n",
    "df_factor_all = df_factor_all[df_factor_all['date'] > '2005-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all.sort_values(['ticker', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all['y'] = df_factor_all.groupby('ticker', as_index=False, group_keys=False)['price'].pct_change(-62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace inf with 9999\n",
    "df_factor_all.replace([np.inf], 9999, inplace=True)\n",
    "df_factor_all.replace([-np.inf], -9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebalance_date(date_list, start_date, end_date, freq='Q'):\n",
    "    next_four_seasons = [start_date]\n",
    "    rebalance_date = start_date\n",
    "    i = 0\n",
    "    while rebalance_date < end_date:\n",
    "        if freq == 'Q':\n",
    "            rebalance_date = start_date + pd.DateOffset(months=3 * (i + 1))\n",
    "        elif freq == 'M':\n",
    "            rebalance_date = start_date + pd.DateOffset(months=1 * (i + 1))\n",
    "        elif freq == 'Y':\n",
    "            rebalance_date = start_date + pd.DateOffset(years=1 * (i + 1))\n",
    "\n",
    "        # check if rebalance_date is in date_list\n",
    "        if rebalance_date in date_list:\n",
    "            next_four_seasons.append(rebalance_date)\n",
    "        else:\n",
    "            # if not, find the next date in date_list\n",
    "            for date in date_list:\n",
    "                if date > rebalance_date:\n",
    "                    # chang np.datetime64 to pd.Timestamp\n",
    "                    rebalance_date = pd.Timestamp(date)\n",
    "                    next_four_seasons.append(rebalance_date)\n",
    "                    break\n",
    "        i += 1\n",
    "    return next_four_seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = np.sort(pd.unique(df_factor_all['date']))\n",
    "rebalance_date_lst = get_rebalance_date(date_list, pd.to_datetime('2005-01-15'), pd.to_datetime('2023-1-15'), freq='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excess_return', 'asset_qoq', 'asset_yoy', 'ppe_qoq', 'ppe_yoy', 'ni_qoq', 'ni_yoy', 'roe', 'roe_yoy', 'roe_4q_sum', 'roe_4q_sum_yoy', 'tobins_q', 'ocf / asset', 'dividend_1Y_sum_yield', 'dividend_2Y_sum_yield', 'dividend_3Y_sum_yield', 'last_dividend_yield']\n"
     ]
    }
   ],
   "source": [
    "factor_columns = df_factor_all.columns.tolist()\n",
    "factor_columns.remove('date')\n",
    "factor_columns.remove('ticker')\n",
    "factor_columns.remove('price')\n",
    "factor_columns.remove('y')\n",
    "print(factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['y']\n",
    "df_factor_all = df_factor_all.dropna(subset=factor_columns + target_cols, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rebalance_date_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████--------------------------------------------| 12.5% Complete\r"
     ]
    }
   ],
   "source": [
    "start_index = 64\n",
    "\n",
    "\n",
    "# name the folder by current date and time\n",
    "folder_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "model_save_path = f'D:/Projects/0_HIDIV/models/{folder_name}'\n",
    "\n",
    "# create a folder to save model\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "\n",
    "\n",
    "total = len(rebalance_date_lst) - start_index  # Total number of iterations\n",
    "\n",
    "print_progress_bar(0, total, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "for i in range(start_index, len(rebalance_date_lst)):\n",
    "    # expanding window\n",
    "    train_date = rebalance_date_lst[0:i]\n",
    "    rebalance_date = rebalance_date_lst[i]\n",
    "\n",
    "    # data valid date = rebalance_date - 62 days\n",
    "    data_valid_date = rebalance_date - pd.DateOffset(days=62)\n",
    "\n",
    "    # remove date in train_date if date > data_valid_date\n",
    "    valid_train_date = [date for date in train_date if date <= data_valid_date]\n",
    "\n",
    "    # 訓練股票\n",
    "    param_search = dict(\n",
    "        learning_rate=[0.01, 0.05, 0.1],\n",
    "        max_depth=[3, 5, 7],\n",
    "        n_estimators=[5, 10, 50, 100, 200],\n",
    "    )\n",
    "\n",
    "    df_factor_all_train = df_factor_all[df_factor_all['date'].isin(train_date)]\n",
    "    \n",
    "    model_stock = XGBRegressor()\n",
    "    gscv = GridSearchCV(\n",
    "        model_stock, param_search, refit=True, scoring=\"neg_root_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    gscv.fit(df_factor_all_train[factor_columns], df_factor_all_train[target_cols])\n",
    "    # timestamp to string format for saving model\n",
    "    rebalance_date = rebalance_date.strftime(\"%Y%m%d\")\n",
    "    gscv.best_estimator_.save_model(f\"{model_save_path}/{rebalance_date}.json\")\n",
    "\n",
    "    # Update Progress Bar\n",
    "    print_progress_bar(i-start_index+1, total, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "print_progress_bar(total, total, prefix = 'Progress:', suffix = 'Complete', length = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excess_return',\n",
       " 'asset_qoq',\n",
       " 'asset_yoy',\n",
       " 'ppe_qoq',\n",
       " 'ppe_yoy',\n",
       " 'ni_qoq',\n",
       " 'ni_yoy',\n",
       " 'roe',\n",
       " 'roe_yoy',\n",
       " 'roe_4q_sum',\n",
       " 'roe_4q_sum_yoy',\n",
       " 'tobins_q',\n",
       " 'ocf / asset',\n",
       " 'dividend_1Y_sum_yield',\n",
       " 'dividend_2Y_sum_yield',\n",
       " 'dividend_3Y_sum_yield',\n",
       " 'last_dividend_yield']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
