{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.append(\"D:/DST/\")\n",
    "import cathay_db as db\n",
    "import utils as ut\n",
    "import financial_statement as fs\n",
    "\n",
    "reload(ut)\n",
    "reload(fs)\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# set max display rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# set max display columns\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# Set the float format to display without scientific notation\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read data from feather file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all = pd.read_feather('data/df_factor_all.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # following is data from tej\n",
    "# df_adjusted_price = pd.read_feather('data/tej_adjusted_price.feather')\n",
    "\n",
    "# # following is data from cmoney\n",
    "# df_price = pd.read_feather('data/cmoney_price.feather')\n",
    "# df_company_info = pd.read_feather('data/cmoney_company_info.feather')\n",
    "\n",
    "# ticker_list = np.sort(pd.unique(df_company_info['股票代號']))\n",
    "\n",
    "# df_price = ut.cmoney_data_clean_up(df_price)\n",
    "# df_price = deepcopy(df_price[df_price['股票代號'].isin(ticker_list)])\n",
    "\n",
    "# df_adjusted_price = ut.tej_data_clean_up(df_adjusted_price)\n",
    "# df_adjusted_price = deepcopy(df_adjusted_price[df_adjusted_price['股票代號'].isin(ticker_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all['y'] = df_factor_all.groupby('ticker', as_index=False, group_keys=False)['price'].pct_change(-62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebalance_date(date_list, start_date, end_date, freq='Q'):\n",
    "    next_four_seasons = [start_date]\n",
    "    rebalance_date = start_date\n",
    "    i = 0\n",
    "    while rebalance_date < end_date:\n",
    "        if freq == 'Q':\n",
    "            rebalance_date = start_date + pd.DateOffset(months=3 * (i + 1))\n",
    "        elif freq == 'M':\n",
    "            rebalance_date = start_date + pd.DateOffset(months=1 * (i + 1))\n",
    "        elif freq == 'Y':\n",
    "            rebalance_date = start_date + pd.DateOffset(years=1 * (i + 1))\n",
    "\n",
    "        # check if rebalance_date is in date_list\n",
    "        if rebalance_date in date_list:\n",
    "            next_four_seasons.append(rebalance_date)\n",
    "        else:\n",
    "            # if not, find the next date in date_list\n",
    "            for date in date_list:\n",
    "                if date > rebalance_date:\n",
    "                    # chang np.datetime64 to pd.Timestamp\n",
    "                    rebalance_date = pd.Timestamp(date)\n",
    "                    next_four_seasons.append(rebalance_date)\n",
    "                    break\n",
    "        i += 1\n",
    "    return next_four_seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = np.sort(pd.unique(df_factor_all['date']))\n",
    "rebalance_date_lst = get_rebalance_date(date_list, pd.to_datetime('2003-01-15'), pd.to_datetime('2020-12-31'), freq='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excess_return', 'asset_qoq', 'asset_yoy', 'ppe_qoq', 'ppe_yoy', 'ni_qoq', 'ni_yoy', 'roe', 'roe_yoy', 'roe_4q_sum', 'roe_4q_sum_yoy', 'tobins_q', 'ocd / asset', 'dividend_1Y_sum_yield', 'dividend_2Y_sum_yield', 'dividend_3Y_sum_yield', 'last_dividend_yield']\n"
     ]
    }
   ],
   "source": [
    "factor_columns = df_factor_all.columns.tolist()\n",
    "factor_columns.remove('date')\n",
    "factor_columns.remove('ticker')\n",
    "factor_columns.remove('price')\n",
    "factor_columns.remove('y')\n",
    "print(factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['y']\n",
    "# df_factor_all = df_factor_all.dropna(subset=factor_columns + target_cols, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all_train = df_factor_all[df_factor_all['date'] == rebalance_date_lst[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "      <th>excess_return</th>\n",
       "      <th>asset_qoq</th>\n",
       "      <th>asset_yoy</th>\n",
       "      <th>ppe_qoq</th>\n",
       "      <th>ppe_yoy</th>\n",
       "      <th>ni_qoq</th>\n",
       "      <th>ni_yoy</th>\n",
       "      <th>roe</th>\n",
       "      <th>roe_yoy</th>\n",
       "      <th>roe_4q_sum</th>\n",
       "      <th>roe_4q_sum_yoy</th>\n",
       "      <th>tobins_q</th>\n",
       "      <th>ocd / asset</th>\n",
       "      <th>dividend_1Y_sum_yield</th>\n",
       "      <th>dividend_2Y_sum_yield</th>\n",
       "      <th>dividend_3Y_sum_yield</th>\n",
       "      <th>last_dividend_yield</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>1101</td>\n",
       "      <td>4.6527</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>1.3250</td>\n",
       "      <td>3.1984</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>6.2793</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>1102</td>\n",
       "      <td>4.5430</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>1.0318</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>1.7324</td>\n",
       "      <td>4.6060</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>1.3969</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12541</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>1103</td>\n",
       "      <td>10.8789</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>1.0085</td>\n",
       "      <td>3.6623</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>7.7575</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.4243</td>\n",
       "      <td>1.0368</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18301</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>1104</td>\n",
       "      <td>4.2977</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>1.0147</td>\n",
       "      <td>1.0213</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.6141</td>\n",
       "      <td>-4.5399</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>-4.1850</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>5.8487</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27167</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>1108</td>\n",
       "      <td>4.9724</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>1.0186</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>-2.9580</td>\n",
       "      <td>-6.6779</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>-0.5047</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820537</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>9937</td>\n",
       "      <td>8.9335</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>1.0162</td>\n",
       "      <td>1.0607</td>\n",
       "      <td>1.0315</td>\n",
       "      <td>1.1808</td>\n",
       "      <td>2.3275</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.1706</td>\n",
       "      <td>0.3122</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>-0.0219</td>\n",
       "      <td>1.0445</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837231</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>9940</td>\n",
       "      <td>4.5306</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>1.0445</td>\n",
       "      <td>1.2684</td>\n",
       "      <td>1.0025</td>\n",
       "      <td>1.2577</td>\n",
       "      <td>1.6248</td>\n",
       "      <td>2.2196</td>\n",
       "      <td>0.4909</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>3.4756</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842991</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>9941</td>\n",
       "      <td>6.1850</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>1.0088</td>\n",
       "      <td>1.0474</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>1.0250</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>1.0740</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>0.1245</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7853731</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>9943</td>\n",
       "      <td>12.9067</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>1.1284</td>\n",
       "      <td>1.0108</td>\n",
       "      <td>1.1318</td>\n",
       "      <td>-5.0646</td>\n",
       "      <td>1.1613</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>8.9687</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>-0.4771</td>\n",
       "      <td>1.5349</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864970</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>9945</td>\n",
       "      <td>1.1176</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>1.0730</td>\n",
       "      <td>1.1817</td>\n",
       "      <td>0.7062</td>\n",
       "      <td>0.7316</td>\n",
       "      <td>-0.0578</td>\n",
       "      <td>-0.2871</td>\n",
       "      <td>-0.0134</td>\n",
       "      <td>-2.2686</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date ticker   price  excess_return  asset_qoq  asset_yoy  \\\n",
       "1021    2004-01-15   1101  4.6527         0.1298     0.9924     0.9864   \n",
       "6781    2004-01-15   1102  4.5430         0.1946     0.9965     1.0318   \n",
       "12541   2004-01-15   1103 10.8789        -0.0057     0.9955     0.9763   \n",
       "18301   2004-01-15   1104  4.2977         0.0760     1.0147     1.0213   \n",
       "27167   2004-01-15   1108  4.9724         0.4056     0.9769     1.0186   \n",
       "...            ...    ...     ...            ...        ...        ...   \n",
       "7820537 2004-01-15   9937  8.9335        -0.0006     1.0162     1.0607   \n",
       "7837231 2004-01-15   9940  4.5306         0.0059     1.0445     1.2684   \n",
       "7842991 2004-01-15   9941  6.1850         0.0342     1.0088     1.0474   \n",
       "7853731 2004-01-15   9943 12.9067         0.0705     0.8080     1.1284   \n",
       "7864970 2004-01-15   9945  1.1176         0.1051     0.9680     0.9386   \n",
       "\n",
       "         ppe_qoq  ppe_yoy  ni_qoq  ni_yoy     roe  roe_yoy  roe_4q_sum  \\\n",
       "1021      0.9862   0.9691  1.3250  3.1984  0.0609   0.0172      0.0450   \n",
       "6781      0.9903   0.9281  1.7324  4.6060  0.1017   0.8827      0.0795   \n",
       "12541     0.9974   0.9905  1.0085  3.6623  0.0642   7.7575      0.0558   \n",
       "18301     0.9923   0.9738  0.6141 -4.5399  0.1098  -4.1850      0.0630   \n",
       "27167     0.9762   0.8988 -2.9580 -6.6779  0.0374   0.1319      0.0084   \n",
       "...          ...      ...     ...     ...     ...      ...         ...   \n",
       "7820537   1.0315   1.1808  2.3275  0.9728  0.1706   0.3122      0.1419   \n",
       "7837231   1.0025   1.2577  1.6248  2.2196  0.4909   0.8766      0.3194   \n",
       "7842991   0.9747   1.0250  0.9736  1.0740  0.1701   0.2173      0.1662   \n",
       "7853731   1.0108   1.1318 -5.0646  1.1613  0.1859   8.9687      0.0841   \n",
       "7864970   1.0730   1.1817  0.7062  0.7316 -0.0578  -0.2871     -0.0134   \n",
       "\n",
       "         roe_4q_sum_yoy  tobins_q  ocd / asset  dividend_1Y_sum_yield  \\\n",
       "1021             6.2793    0.7606       0.0543                 0.0055   \n",
       "6781             1.3969    0.9242       0.0314                 0.0248   \n",
       "12541            0.4243    1.0368      -0.0007                 0.0000   \n",
       "18301            5.8487    0.5575       0.0184                 0.0000   \n",
       "27167           -0.5047    0.7667       0.0277                 0.0122   \n",
       "...                 ...       ...          ...                    ...   \n",
       "7820537         -0.0219    1.0445       0.1017                 0.0630   \n",
       "7837231          0.1987    3.4756       0.2071                 0.0288   \n",
       "7842991          0.1245    0.8103       0.0945                 0.0673   \n",
       "7853731         -0.4771    1.5349       0.2252                 0.0469   \n",
       "7864970         -2.2686    0.4564       0.1151                 0.0000   \n",
       "\n",
       "         dividend_2Y_sum_yield  dividend_3Y_sum_yield  last_dividend_yield  \\\n",
       "1021                    0.0055                 0.0055               0.0000   \n",
       "6781                    0.0347                 0.0470               0.0000   \n",
       "12541                   0.0000                 0.0000               0.0000   \n",
       "18301                   0.0000                 0.0071               0.0000   \n",
       "27167                   0.0122                 0.0122               0.0000   \n",
       "...                        ...                    ...                  ...   \n",
       "7820537                 0.0925                 0.1063               0.0000   \n",
       "7837231                 0.0452                 0.0539               0.0000   \n",
       "7842991                 0.1347                 0.1953               0.0000   \n",
       "7853731                 0.1250                 0.1445               0.0000   \n",
       "7864970                 0.0000                 0.0000               0.0000   \n",
       "\n",
       "              y  \n",
       "1021     0.0225  \n",
       "6781    -0.0776  \n",
       "12541    0.0939  \n",
       "18301   -0.0310  \n",
       "27167   -0.2969  \n",
       "...         ...  \n",
       "7820537  0.0496  \n",
       "7837231 -0.1576  \n",
       "7842991 -0.0660  \n",
       "7853731  0.0449  \n",
       "7864970 -0.2767  \n",
       "\n",
       "[484 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = ['y']\n",
    "df_factor_all_train.dropna(subset=factor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "      <th>excess_return</th>\n",
       "      <th>asset_qoq</th>\n",
       "      <th>asset_yoy</th>\n",
       "      <th>ppe_qoq</th>\n",
       "      <th>ppe_yoy</th>\n",
       "      <th>ni_qoq</th>\n",
       "      <th>ni_yoy</th>\n",
       "      <th>roe</th>\n",
       "      <th>roe_yoy</th>\n",
       "      <th>roe_4q_sum</th>\n",
       "      <th>roe_4q_sum_yoy</th>\n",
       "      <th>tobins_q</th>\n",
       "      <th>ocd / asset</th>\n",
       "      <th>dividend_1Y_sum_yield</th>\n",
       "      <th>dividend_2Y_sum_yield</th>\n",
       "      <th>dividend_3Y_sum_yield</th>\n",
       "      <th>last_dividend_yield</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1653396</th>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>2330</td>\n",
       "      <td>25.4291</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>1.0533</td>\n",
       "      <td>1.0126</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>1.2931</td>\n",
       "      <td>4.7999</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>4.6029</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.4752</td>\n",
       "      <td>3.6870</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date ticker   price  excess_return  asset_qoq  asset_yoy  \\\n",
       "1653396 2004-01-15   2330 25.4291         0.1254     1.0533     1.0126   \n",
       "\n",
       "         ppe_qoq  ppe_yoy  ni_qoq  ni_yoy    roe  roe_yoy  roe_4q_sum  \\\n",
       "1653396   0.9821   0.8841  1.2931  4.7999 0.2023   4.6029      0.1127   \n",
       "\n",
       "         roe_4q_sum_yoy  tobins_q  ocd / asset  dividend_1Y_sum_yield  \\\n",
       "1653396          0.4752    3.6870       0.2020                 0.0000   \n",
       "\n",
       "         dividend_2Y_sum_yield  dividend_3Y_sum_yield  last_dividend_yield  \\\n",
       "1653396                 0.0000                 0.0000               0.0000   \n",
       "\n",
       "             y  \n",
       "1653396 0.0984  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_factor_all_train[df_factor_all_train['ticker'] == '2330']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excess_return 1715\n",
      "asset_qoq 1671\n",
      "asset_yoy 1673\n",
      "ppe_qoq 1671\n",
      "ppe_yoy 1673\n",
      "ni_qoq 1671\n",
      "ni_yoy 1671\n",
      "roe 1671\n",
      "roe_yoy 1671\n",
      "roe_4q_sum 1671\n",
      "roe_4q_sum_yoy 1664\n",
      "tobins_q 1504\n",
      "ocd / asset 1673\n",
      "dividend_1Y_sum_yield 1679\n",
      "dividend_2Y_sum_yield 1617\n",
      "dividend_3Y_sum_yield 1574\n",
      "last_dividend_yield 1696\n"
     ]
    }
   ],
   "source": [
    "for col_name in factor_columns:\n",
    "    print(col_name, len(df_factor_all_train[df_factor_all_train[col_name].isna() == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00')]\n",
      "rebalance_date : 2004-01-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00')]\n",
      "rebalance_date : 2004-04-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00')]\n",
      "rebalance_date : 2004-07-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00')]\n",
      "rebalance_date : 2004-10-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00')]\n",
      "rebalance_date : 2005-01-17 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00')]\n",
      "rebalance_date : 2005-04-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00')]\n",
      "rebalance_date : 2005-07-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00')]\n",
      "rebalance_date : 2005-10-17 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00')]\n",
      "rebalance_date : 2006-01-16 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00')]\n",
      "rebalance_date : 2006-04-17 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00')]\n",
      "rebalance_date : 2006-07-17 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00')]\n",
      "rebalance_date : 2006-10-16 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00')]\n",
      "rebalance_date : 2007-01-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00')]\n",
      "rebalance_date : 2007-04-16 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00')]\n",
      "rebalance_date : 2007-07-16 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00')]\n",
      "rebalance_date : 2007-10-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00')]\n",
      "rebalance_date : 2008-01-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00')]\n",
      "rebalance_date : 2008-04-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00')]\n",
      "rebalance_date : 2008-07-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00')]\n",
      "rebalance_date : 2008-10-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00')]\n",
      "rebalance_date : 2009-01-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00'), Timestamp('2009-01-15 00:00:00')]\n",
      "rebalance_date : 2009-04-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00'), Timestamp('2009-01-15 00:00:00'), Timestamp('2009-04-15 00:00:00')]\n",
      "rebalance_date : 2009-07-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00'), Timestamp('2009-01-15 00:00:00'), Timestamp('2009-04-15 00:00:00'), Timestamp('2009-07-15 00:00:00')]\n",
      "rebalance_date : 2009-10-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00'), Timestamp('2009-01-15 00:00:00'), Timestamp('2009-04-15 00:00:00'), Timestamp('2009-07-15 00:00:00'), Timestamp('2009-10-15 00:00:00')]\n",
      "rebalance_date : 2010-01-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00'), Timestamp('2009-01-15 00:00:00'), Timestamp('2009-04-15 00:00:00'), Timestamp('2009-07-15 00:00:00'), Timestamp('2009-10-15 00:00:00'), Timestamp('2010-01-15 00:00:00')]\n",
      "rebalance_date : 2010-04-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00'), Timestamp('2009-01-15 00:00:00'), Timestamp('2009-04-15 00:00:00'), Timestamp('2009-07-15 00:00:00'), Timestamp('2009-10-15 00:00:00'), Timestamp('2010-01-15 00:00:00'), Timestamp('2010-04-15 00:00:00')]\n",
      "rebalance_date : 2010-07-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00'), Timestamp('2009-01-15 00:00:00'), Timestamp('2009-04-15 00:00:00'), Timestamp('2009-07-15 00:00:00'), Timestamp('2009-10-15 00:00:00'), Timestamp('2010-01-15 00:00:00'), Timestamp('2010-04-15 00:00:00'), Timestamp('2010-07-15 00:00:00')]\n",
      "rebalance_date : 2010-10-15 00:00:00\n",
      "train_date : [Timestamp('2003-01-15 00:00:00'), Timestamp('2003-04-15 00:00:00'), Timestamp('2003-07-15 00:00:00'), Timestamp('2003-10-15 00:00:00'), Timestamp('2004-01-15 00:00:00'), Timestamp('2004-04-15 00:00:00'), Timestamp('2004-07-15 00:00:00'), Timestamp('2004-10-15 00:00:00'), Timestamp('2005-01-17 00:00:00'), Timestamp('2005-04-15 00:00:00'), Timestamp('2005-07-15 00:00:00'), Timestamp('2005-10-17 00:00:00'), Timestamp('2006-01-16 00:00:00'), Timestamp('2006-04-17 00:00:00'), Timestamp('2006-07-17 00:00:00'), Timestamp('2006-10-16 00:00:00'), Timestamp('2007-01-15 00:00:00'), Timestamp('2007-04-16 00:00:00'), Timestamp('2007-07-16 00:00:00'), Timestamp('2007-10-15 00:00:00'), Timestamp('2008-01-15 00:00:00'), Timestamp('2008-04-15 00:00:00'), Timestamp('2008-07-15 00:00:00'), Timestamp('2008-10-15 00:00:00'), Timestamp('2009-01-15 00:00:00'), Timestamp('2009-04-15 00:00:00'), Timestamp('2009-07-15 00:00:00'), Timestamp('2009-10-15 00:00:00'), Timestamp('2010-01-15 00:00:00'), Timestamp('2010-04-15 00:00:00'), Timestamp('2010-07-15 00:00:00'), Timestamp('2010-10-15 00:00:00')]\n",
      "rebalance_date : 2011-01-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "180 fits failed out of a total of 225.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:13] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:14] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:15] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:16] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:17] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:18] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:19] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:21] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:22] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:23] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:24] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:26] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:27] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:28] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:30] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:31] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:32] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:33] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:35] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:37] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 970, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 420, in _from_pandas_df\n",
      "    return _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 213, in _from_numpy_array\n",
      "    _check_call(\n",
      "  File \"d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:53:39] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[10:53:39] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 27\u001b[0m\n\u001b[0;32m     22\u001b[0m model_stock \u001b[39m=\u001b[39m XGBRegressor()\n\u001b[0;32m     23\u001b[0m gscv \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[0;32m     24\u001b[0m     model_stock, param_search, refit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneg_root_mean_squared_error\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m gscv\u001b[39m.\u001b[39;49mfit(df_factor_all_train[factor_columns], df_factor_all_train[target_cols])\n\u001b[0;32m     28\u001b[0m \u001b[39m# timestamp to string format for saving model\u001b[39;00m\n\u001b[0;32m     29\u001b[0m rebalance_date \u001b[39m=\u001b[39m rebalance_date\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:933\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    931\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    932\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 933\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    934\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:988\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[39mwith\u001b[39;00m config_context(verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity):\n\u001b[0;32m    987\u001b[0m     evals_result: TrainingCallback\u001b[39m.\u001b[39mEvalsLog \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 988\u001b[0m     train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m    989\u001b[0m         missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m    990\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    991\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    992\u001b[0m         group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    993\u001b[0m         qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    994\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    995\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m    996\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m    997\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[0;32m    998\u001b[0m         sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[0;32m    999\u001b[0m         base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[0;32m   1000\u001b[0m         eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1001\u001b[0m         eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1002\u001b[0m         create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[0;32m   1003\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[0;32m   1004\u001b[0m         feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[0;32m   1005\u001b[0m     )\n\u001b[0;32m   1006\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1008\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    429\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[0;32m    430\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    445\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[0;32m    446\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[0;32m    449\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    450\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    451\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[0;32m    452\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[0;32m    453\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    454\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m    455\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m    456\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[0;32m    457\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    458\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    459\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    460\u001b[0m     )\n\u001b[0;32m    462\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[0;32m    464\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:908\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    907\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[39mreturn\u001b[39;00m DMatrix(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[39m=\u001b[39m dispatch_data_backend(\n\u001b[0;32m    744\u001b[0m     data,\n\u001b[0;32m    745\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m    746\u001b[0m     threads\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnthread,\n\u001b[0;32m    747\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[0;32m    748\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    749\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    750\u001b[0m )\n\u001b[0;32m    751\u001b[0m \u001b[39massert\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m handle\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py:970\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n\u001b[0;32m    969\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[0;32m    971\u001b[0m                            feature_names, feature_types)\n\u001b[0;32m    972\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_series(data):\n\u001b[0;32m    973\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_series(\n\u001b[0;32m    974\u001b[0m         data, missing, threads, enable_categorical, feature_names, feature_types\n\u001b[0;32m    975\u001b[0m     )\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py:420\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_pandas_df\u001b[39m(\n\u001b[0;32m    410\u001b[0m     data: DataFrame,\n\u001b[0;32m    411\u001b[0m     enable_categorical: \u001b[39mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    416\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[0;32m    417\u001b[0m     data, feature_names, feature_types \u001b[39m=\u001b[39m _transform_pandas_df(\n\u001b[0;32m    418\u001b[0m         data, enable_categorical, feature_names, feature_types\n\u001b[0;32m    419\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\data.py:213\u001b[0m, in \u001b[0;36m_from_numpy_array\u001b[1;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    208\u001b[0m args \u001b[39m=\u001b[39m {\n\u001b[0;32m    209\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(missing),\n\u001b[0;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnthread\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mint\u001b[39m(nthread),\n\u001b[0;32m    211\u001b[0m }\n\u001b[0;32m    212\u001b[0m config \u001b[39m=\u001b[39m \u001b[39mbytes\u001b[39m(json\u001b[39m.\u001b[39mdumps(args), \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m _check_call(\n\u001b[0;32m    214\u001b[0m     _LIB\u001b[39m.\u001b[39;49mXGDMatrixCreateFromDense(\n\u001b[0;32m    215\u001b[0m         _array_interface(data),\n\u001b[0;32m    216\u001b[0m         config,\n\u001b[0;32m    217\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(handle),\n\u001b[0;32m    218\u001b[0m     )\n\u001b[0;32m    219\u001b[0m )\n\u001b[0;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m handle, feature_names, feature_types\n",
      "File \u001b[1;32md:\\Projects\\0_HIDIV\\venv\\Lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [10:53:39] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`"
     ]
    }
   ],
   "source": [
    "start_index = 4\n",
    "# rebalance_date_lst\n",
    "model_save_path = 'D:/Projects/0_HIDIV/models'\n",
    "\n",
    "for i in range(start_index, len(rebalance_date_lst)):\n",
    "    # expanding window\n",
    "    train_date = rebalance_date_lst[0:i]\n",
    "    rebalance_date = rebalance_date_lst[i]\n",
    "\n",
    "    print(\"train_date : {}\".format(train_date))\n",
    "    print(\"rebalance_date : {}\".format(rebalance_date))\n",
    "\n",
    "    # 訓練股票\n",
    "    param_search = dict(\n",
    "        learning_rate=[0.01, 0.05, 0.1],\n",
    "        max_depth=[3, 5, 7],\n",
    "        n_estimators=[5, 10, 50, 100, 200],\n",
    "    )\n",
    "\n",
    "    df_factor_all_train = df_factor_all[df_factor_all['date'].isin(train_date)]\n",
    "    \n",
    "    model_stock = XGBRegressor()\n",
    "    gscv = GridSearchCV(\n",
    "        model_stock, param_search, refit=True, scoring=\"neg_root_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    gscv.fit(df_factor_all_train[factor_columns], df_factor_all_train[target_cols])\n",
    "    # timestamp to string format for saving model\n",
    "    rebalance_date = rebalance_date.strftime(\"%Y%m%d\")\n",
    "    gscv.best_estimator_.save_model(f\"{model_save_path}/{rebalance_date}.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excess_return',\n",
       " 'asset_qoq',\n",
       " 'asset_yoy',\n",
       " 'ppe_qoq',\n",
       " 'ppe_yoy',\n",
       " 'ni_qoq',\n",
       " 'ni_yoy',\n",
       " 'roe',\n",
       " 'roe_yoy',\n",
       " 'roe_4q_sum',\n",
       " 'roe_4q_sum_yoy',\n",
       " 'tobins_q',\n",
       " 'ocd / asset',\n",
       " 'dividend_1Y_sum_yield',\n",
       " 'dividend_2Y_sum_yield',\n",
       " 'dividend_3Y_sum_yield',\n",
       " 'last_dividend_yield']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
