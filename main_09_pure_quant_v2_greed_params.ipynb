{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as mtick\n",
    "import itertools\n",
    "import json\n",
    "import dataframe_image as dfi\n",
    "from PIL import Image\n",
    "\n",
    "from importlib import reload\n",
    "import src.cathay_db as db\n",
    "import src.utils as ut\n",
    "import src.financial_statement as fs\n",
    "reload(ut)\n",
    "reload(fs)\n",
    "\n",
    "# set max display rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "# set max display columns\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "# Set the float format to display without scientific notation\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "# Set global font to 'Microsoft JhengHei'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Microsoft JhengHei']\n",
    "\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(df, cell_heights):\n",
    "    fig, ax = plt.subplots()\n",
    "    formatted_data = df.round(2).values.tolist()\n",
    "    labels = df.columns.tolist()\n",
    "    \n",
    "    table = ax.table(cellText=formatted_data, colLabels=labels, colWidths=[.5]*len(labels), loc='center')\n",
    "\n",
    "    cell_dict = table.get_celld()\n",
    "    for i, label in enumerate(labels):\n",
    "        cell_dict[(0,i)].set_height(cell_heights[0])\n",
    "        for j in range(1, len(formatted_data)+1):\n",
    "            cell_dict[(j,i)].set_height(cell_heights[1])\n",
    "\n",
    "    table.set_fontsize(25)\n",
    "    ax.axis('off')\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def top_n(df, n=5, columns=['last_dividend_yield', 'predict_rank'], ascending=[False, True]):\n",
    "    return df.sort_values(by=columns, ascending=ascending).head(n)\n",
    "\n",
    "def get_daily_portfolio(df_rebalance, reb_lst, df_price, weight_type = 'vw', adjust_type = [\"equal\", \"equal\"],ratio: float = 0.5, weight_ratio: int = 1, rank_col: str = \"rank\", weight_col: str = \"weight\", weight_by_yields = False, replace_bottom='min'):\n",
    "\n",
    "    df_portfolio_value_all = pd.DataFrame([])\n",
    "    df_portfolio_detail_start = pd.DataFrame([])\n",
    "    df_portfolio_detail_end = pd.DataFrame([])\n",
    "    df_portfolio_detail_all = pd.DataFrame([])\n",
    "    portfolio_quarterly_return = []\n",
    "    portfolio_value = 1000000000\n",
    "\n",
    "    for i in range(len(reb_lst) - 1):\n",
    "\n",
    "        df_portfolio = df_rebalance.copy()\n",
    "\n",
    "        df_portfolio_copy = df_portfolio[df_portfolio['date'] == reb_lst[i]].copy()\n",
    "        df_portfolio_copy['weight'] = 1 / df_portfolio_copy.groupby('date')['ticker'].transform('count')\n",
    "        df_portfolio_copy = ut.adjust_weights(df_portfolio_copy, adjust_type, ratio, weight_ratio, rank_col, weight_col)\n",
    "\n",
    "        if weight_by_yields:\n",
    "            if replace_bottom == 'min':\n",
    "                df_portfolio_copy = ut.weight_by_yields(df_portfolio_copy, 5, 'adjusted_weight', 'min')\n",
    "            if replace_bottom == 'q20':\n",
    "                df_portfolio_copy = ut.weight_by_yields(df_portfolio_copy, 5, 'adjusted_weight', 'q20')\n",
    "                \n",
    "            use_weight_col = 'weight_by_yields'\n",
    "        else:\n",
    "            use_weight_col = 'adjusted_weight'\n",
    "\n",
    "        df_portfolio_copy.sort_values('ticker', inplace=True)\n",
    "        ticker_list = df_portfolio_copy['ticker'].unique()\n",
    "\n",
    "        if weight_type == 'ew':\n",
    "            if len(df_portfolio_value_all) == 0:\n",
    "                df_portfolio_copy['portfolio_value'] = portfolio_value / len(ticker_list)\n",
    "            else:\n",
    "                df_portfolio_copy['portfolio_value'] = df_portfolio_value_all['portfolio_value'].iloc[-1] / len(ticker_list)\n",
    "\n",
    "        if weight_type == 'vw':\n",
    "            if len(df_portfolio_value_all) == 0:\n",
    "                df_portfolio_copy['portfolio_value'] = portfolio_value * df_portfolio_copy[use_weight_col]\n",
    "            else:\n",
    "                df_portfolio_copy['portfolio_value'] = df_portfolio_value_all['portfolio_value'].iloc[-1] * df_portfolio_copy[use_weight_col]\n",
    "\n",
    "\n",
    "        df_portfolio_copy.reset_index(drop=True, inplace=True)\n",
    "        # give the weight to each stock by market cap\n",
    "        # df_portfolio_copy['portfolio_value'] = df_portfolio_copy['portfolio_value'] * df_portfolio_copy['market_cap'] / df_portfolio_copy['market_cap'].sum()\n",
    "\n",
    "        df_price_period = df_price[(df_price['ticker'].isin(ticker_list)) & (df_price['date'] >= reb_lst[i]) & (df_price['date'] <= reb_lst[i + 1])].copy()\n",
    "        # check if there is price missing\n",
    "\n",
    "        if df_price_period.groupby('ticker')['date'].count().max() != df_price_period.groupby('ticker')['date'].count().min():\n",
    "            print('fuck')\n",
    "\n",
    "\n",
    "        df_price_period.sort_values(['ticker','date'], inplace=True)\n",
    "        df_price_period.reset_index(drop=True, inplace=True)\n",
    "        df_price_period['price_shift'] = df_price_period.groupby('ticker')['price'].shift(1)\n",
    "        df_price_period['rt'] = df_price_period['price'] / df_price_period['price_shift']\n",
    "        df_price_period['rt'].fillna(1, inplace=True)\n",
    "        # pivot the rt\n",
    "        df_rt_pivot = df_price_period.pivot(index='date', columns='ticker', values='rt').copy()\n",
    "\n",
    "        df_portfolio_value = df_rt_pivot.cumprod().mul(df_portfolio_copy['portfolio_value'].values).sum(axis=1).reset_index().rename(columns={0:'portfolio_value'})\n",
    "        # print return by sub the last value by the first value\n",
    "        portfolio_quarterly_return.append(df_portfolio_value['portfolio_value'].iloc[-1] / df_portfolio_value['portfolio_value'].iloc[0] - 1)\n",
    "\n",
    "        df_portfolio_value_all = pd.concat([df_portfolio_value_all, df_portfolio_value], axis=0)\n",
    "\n",
    "        df_portfolio_detail_start = pd.concat([df_portfolio_detail_start, pd.melt(df_rt_pivot.cumprod().mul(df_portfolio_copy['portfolio_value'].values).iloc[[0],:].reset_index(), id_vars = ['date'])], axis=0)\n",
    "        df_portfolio_detail_end = pd.concat([df_portfolio_detail_end, pd.melt(df_rt_pivot.cumprod().mul(df_portfolio_copy['portfolio_value'].values).iloc[[-1],:].reset_index(), id_vars = ['date'])], axis=0)\n",
    "        df_portfolio_detail_all = pd.concat([df_portfolio_detail_all, pd.melt(df_rt_pivot.cumprod().mul(df_portfolio_copy['portfolio_value'].values).reset_index(), id_vars = ['date'])], axis=0)\n",
    "\n",
    "    df_portfolio_value_all = df_portfolio_value_all.copy()\n",
    "    df_portfolio_value_all['date'] = pd.to_datetime(df_portfolio_value_all['date'])\n",
    "    df_portfolio_value_all['portfolio_value'] = df_portfolio_value_all['portfolio_value'].round(0)\n",
    "    df_portfolio_value_all = df_portfolio_value_all.drop_duplicates()\n",
    "\n",
    "    return df_portfolio_value_all, df_portfolio_detail_start, df_portfolio_detail_end, df_portfolio_detail_all\n",
    "\n",
    "def calc_sharpe_ratio(series):\n",
    "    return ((series.pct_change().mean() * 252) / (series.pct_change().std() * np.sqrt(252)))\n",
    "\n",
    "def get_rebalance_dates_by_month_day(date_list, months, day):\n",
    "    # Ensure month inputs are integers and sort them\n",
    "    months = sorted([int(month) for month in months])\n",
    "    \n",
    "    start_year = min(date_list).year\n",
    "    end_year = max(date_list).year\n",
    "    rebalance_dates = []\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in months:\n",
    "            proposed_date = pd.Timestamp(year=year, month=month, day=day)\n",
    "            \n",
    "            # check if proposed_date is in date_list\n",
    "            if proposed_date in date_list:\n",
    "                rebalance_dates.append(proposed_date)\n",
    "            else:\n",
    "                # if not, find the next available date in date_list for that year and month\n",
    "                next_available_dates = [date for date in date_list if date >= proposed_date and date.year == year]\n",
    "                if next_available_dates:\n",
    "                    rebalance_dates.append(next_available_dates[0])\n",
    "    \n",
    "    return rebalance_dates\n",
    "\n",
    "# calc the CAGR with the last value and the first value of portfolio value\n",
    "def calculate_cagr(series):\n",
    "    # get the last value of portfolio value\n",
    "    last_value = series.iloc[-1]\n",
    "    # get the first value of portfolio value\n",
    "    first_value = series.iloc[0]\n",
    "    # get the total number of years\n",
    "    num_years = len(series) / 252\n",
    "    # calc the CAGR\n",
    "    cagr = (last_value / first_value)**(1/num_years) - 1\n",
    "    return cagr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['start_index', 'rebalance_date_lst', 'factor_columns', 'target_cols', 'model_save_path', 'param_search', 'fit_params'])\n",
      "['asset_qoq', 'asset_yoy', 'ni_qoq', 'ni_yoy', 'roe', 'roe_yoy', 'roe_4q_sum', 'roe_4q_sum_yoy', 'tobins_q', 'ocf / asset', '20_d_return', '40_d_return', '60_d_return', 'dividend_1Y_sum_yield', 'dividend_2Y_sum_yield', 'dividend_3Y_sum_yield', 'last_dividend_yield']\n"
     ]
    }
   ],
   "source": [
    "# select model \n",
    "model_folder_name = '20230724_091431'\n",
    "# load setting from data/model/model_folder_name/setting.json\n",
    "setting = ut.load_json(f'./data/model/{model_folder_name}/setting.json')\n",
    "\n",
    "print(setting.keys())\n",
    "print(setting['factor_columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_adjusted_price = pd.read_feather('data/df_adjusted_price.feather')\n",
    "# df_adjusted_price.drop_duplicates(inplace=True)\n",
    "# df_adjusted_price.reset_index(drop=True, inplace=True)\n",
    "# df_adjusted_price_pivot = df_adjusted_price.pivot(index='年月日',columns='股票代號',values='收盤價(元)').fillna(method='ffill')\n",
    "# df_adjusted_price = df_adjusted_price_pivot.reset_index().melt(id_vars='年月日', var_name='股票代號', value_name='收盤價(元)')\n",
    "\n",
    "# # save the df_adjusted_price to feather\n",
    "# df_adjusted_price.to_feather('data/quant/df_adjusted_price.feather')\n",
    "\n",
    "# read the df_adjusted_price from feather\n",
    "df_adjusted_price = pd.read_feather('data/quant/df_adjusted_price.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_factor from data/model/model_folder_name/df_factor_all.feather\n",
    "df_factor_all = pd.read_feather(f'./data/model/{model_folder_name}/df_factor_all_testing.feather')\n",
    "# df_factor_all = pd.read_feather(f'data/df_factor_all.feather')\n",
    "\n",
    "df_factor_all = df_factor_all.reset_index(drop=True)\n",
    "df_factor_all = deepcopy(df_factor_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liquidity Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_price = pd.read_feather('data/cmoney_price.feather')\n",
    "# df_price = ut.cmoney_data_clean_up(df_price)\n",
    "# df_price['日期'] = pd.to_datetime(df_price['日期'])\n",
    "# df_price.reset_index(drop = True).to_feather('data/quant/cmoney_price.feather')\n",
    "\n",
    "# df_price_sub = df_price[['日期','股票代號','收盤價','成交量','成交金額(千)']].copy()\n",
    "# df_price_sub.columns = ['date','ticker','close','volume','amount(k)']\n",
    "# df_price_sub.sort_values([\"ticker\", \"date\"], inplace=True)\n",
    "# df_price_sub.reset_index(drop=True, inplace=True)\n",
    "# df_price_sub['20_d_mean_amount_k'] = df_price_sub.groupby('ticker', as_index=False)['amount(k)'].rolling(20).mean()['amount(k)']\n",
    "# df_price_sub['252_d_mean_amount_k'] = df_price_sub.groupby('ticker', as_index=False)['amount(k)'].rolling(252).mean()['amount(k)']\n",
    "# df_price_sub['252_d_median_amount_k'] = df_price_sub.groupby('ticker', as_index=False)['amount(k)'].rolling(252).median()['amount(k)']\n",
    "# df_price_sub['60_d_median_amount_k'] = df_price_sub.groupby('ticker', as_index=False)['amount(k)'].rolling(60).median()['amount(k)']\n",
    "# df_price_sub['20_d_median_amount_k'] = df_price_sub.groupby('ticker', as_index=False)['amount(k)'].rolling(20).median()['amount(k)']\n",
    "# df_price_sub.reset_index(drop = True).to_feather('data/quant/cmoney_price_sub.feather')\n",
    "\n",
    "\n",
    "# df_price_div = df_price[['日期','股票代號','收盤價']].copy()\n",
    "# df_price_div.columns = ['date','ticker','unadj_price']\n",
    "# df_price_div['date'] = pd.to_datetime(df_price_div['date'])\n",
    "# # sort by date for shift\n",
    "# df_price_div.sort_values(['ticker','date'],inplace=True)\n",
    "# # shift to get last day price\n",
    "# df_price_div['yesterday_price'] = df_price_div.groupby('ticker')['unadj_price'].shift(1)\n",
    "# df_price_div['unadj_price'] = df_price_div['unadj_price'].astype(float)\n",
    "# df_price_div['yesterday_price'] = df_price_div['yesterday_price'].astype(float)\n",
    "\n",
    "# # df_price_div to feather\n",
    "# df_price_div.reset_index(drop = True).to_feather('data/quant/cmoney_price_div.feather')\n",
    "\n",
    "df_price = pd.read_feather('data/quant/cmoney_price.feather')\n",
    "df_price_sub = pd.read_feather('data/quant/cmoney_price_sub.feather')\n",
    "df_price_div = pd.read_feather('data/quant/cmoney_price_div.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_price_sub_backtest = df_price_sub[['date','ticker','close']].copy()\n",
    "# # change close to price\n",
    "# df_price_sub_backtest.rename(columns={'close':'price'}, inplace=True)\n",
    "# df_price_sub_backtest['price'] = df_price_sub_backtest['price'].astype(float)\n",
    "\n",
    "# df_price_sub_backtest.drop_duplicates(inplace=True)\n",
    "# df_price_sub_backtest.reset_index(drop=True, inplace=True)\n",
    "# df_price_sub_backtest_pivot = df_price_sub_backtest.pivot(index='date',columns='ticker',values='price').fillna(method='ffill')\n",
    "# df_price_sub_backtest = df_price_sub_backtest_pivot.reset_index().melt(id_vars='date', var_name='ticker', value_name='price')\n",
    "\n",
    "# df_price_sub_backtest.to_feather('data/quant/df_price_sub_backtest.feather')\n",
    "# read feather\n",
    "df_price_sub_backtest = pd.read_feather('data/quant/df_price_sub_backtest.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_factor from data/model/model_folder_name/df_factor_all.feather\n",
    "df_factor_all = pd.read_feather(f'./data/model/{model_folder_name}/df_factor_all_testing.feather')\n",
    "\n",
    "\n",
    "reb_lst = get_rebalance_dates_by_month_day(df_factor_all[df_factor_all['date'] > '2005-02-01']['date'].unique(), [2,5,7,11], 25)\n",
    "\n",
    "df_model_mapping = pd.DataFrame()\n",
    "df_model_mapping['rebalance_date'] = reb_lst\n",
    "\n",
    "# merge the df_model_mapping and df_factor_all\n",
    "df_factor_all = pd.merge(df_factor_all, df_model_mapping, left_on='date', right_on='rebalance_date', how='left')\n",
    "df_factor_all = df_factor_all.sort_values(['date','ticker']).reset_index(drop=True)\n",
    "# df_factor_all['model_path'].fillna(method='ffill', inplace=True)\n",
    "df_factor_all['rebalance_date'].fillna(method='ffill', inplace=True)\n",
    "factor_columns = setting['factor_columns']\n",
    "df_factor_all.dropna(subset=factor_columns, inplace=True)\n",
    "\n",
    "df_factor_all = df_factor_all.reset_index(drop=True)\n",
    "\n",
    "df_rebalance_date = pd.DataFrame()\n",
    "# df_rebalance_date['date'] = setting['rebalance_date_lst']\n",
    "df_rebalance_date['date'] = reb_lst\n",
    "# set date to datetime format\n",
    "df_rebalance_date['date'] = pd.to_datetime(df_rebalance_date['date'])\n",
    "df_backtest_return = pd.merge(df_rebalance_date, df_adjusted_price, how='left', left_on='date', right_on='年月日')[['date','股票代號','收盤價(元)']].copy()\n",
    "\n",
    "df_backtest_return.rename(columns={'股票代號':'ticker'}, inplace=True)\n",
    "df_backtest_return.rename(columns={'收盤價(元)':'price'}, inplace=True)\n",
    "df_backtest_return['price'] = df_backtest_return['price'].astype(float)\n",
    "df_backtest_return['price_shift'] = df_backtest_return.groupby('ticker', group_keys=False)['price'].shift(-1)\n",
    "df_backtest_return['rebalance_period_return'] = df_backtest_return['price_shift'] / df_backtest_return['price'] - 1\n",
    "\n",
    "df_factor_all = df_factor_all.merge(df_backtest_return[['date','ticker','rebalance_period_return']], on=['date','ticker'], how='left')\n",
    "df_factor_all_select = df_factor_all.copy()\n",
    "\n",
    "df_factor_all.to_feather(f'./data/model/{model_folder_name}/df_factor_all_select.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all_reb = df_factor_all[df_factor_all['date'] == df_factor_all['rebalance_date']].copy()\n",
    "df_factor_all_reb.sort_values(['date','ticker'], inplace=True)\n",
    "df_factor_all_reb.reset_index(drop=True, inplace=True)\n",
    "df_factor_all_reb['market_cap_billion'] = df_factor_all_reb['market_cap'] / 1000000\n",
    "df_factor_all_reb['market_cap_rank'] = df_factor_all_reb.groupby('date')['market_cap'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all_amount_rank = df_factor_all.merge(df_price_sub[['date','ticker','20_d_mean_amount_k','252_d_mean_amount_k']], on = ['date','ticker'], how = 'left')\n",
    "df_factor_all_amount_rank['amount_rank_20'] = df_factor_all_amount_rank.groupby('date')['20_d_mean_amount_k'].rank(ascending=False, pct=True)\n",
    "df_factor_all_amount_rank['amount_rank_20'] = df_factor_all_amount_rank.groupby('date')['20_d_mean_amount_k'].rank(ascending=False, pct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PORTFOLIO TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 200 40 0 0\n",
      "最小檔數:  64\n",
      "取得再平衡股票清單...\n",
      "使用再平衡清單回測 Total Return...\n",
      "績效評核 - TR...\n",
      "beta: 1.03\n",
      "alpha TR: 2.25%\n",
      "計算 股數殖利率...\n",
      "平均年化周轉率:  111.12\n",
      "平均每年殖利率 5.77\n",
      "計算PR殖利率...\n",
      "近五年指數股息率: \n",
      "year\n",
      "2018   5.4500\n",
      "2019   6.6300\n",
      "2020   6.7300\n",
      "2021   5.5100\n",
      "2022   9.4500\n",
      "Name: dividend, dtype: float64\n",
      "近五年指數平均股息率:  6.75\n",
      "近 5 年 PR 指數累計報酬:  140.3\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.44223876]\n",
      "近 5 年 TR 指數累計報酬:  191.62\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.74987709]\n",
      "近 8 年 TR 指數累計報酬:  281.24\n",
      "近 8 年 加權 PR 指數累計報酬:  [2.21310936]\n",
      "前5檔最大總和權重 2023-03-01 00:00:00 0.2272\n",
      "58.15480346543946\n",
      "50 250 40 0 0\n",
      "最小檔數:  72\n",
      "取得再平衡股票清單...\n",
      "使用再平衡清單回測 Total Return...\n",
      "績效評核 - TR...\n",
      "beta: 1.03\n",
      "alpha TR: 2.86%\n",
      "計算 股數殖利率...\n",
      "平均年化周轉率:  110.36\n",
      "平均每年殖利率 6.11\n",
      "計算PR殖利率...\n",
      "近五年指數股息率: \n",
      "year\n",
      "2018    5.8400\n",
      "2019    7.0100\n",
      "2020    6.9600\n",
      "2021    6.1500\n",
      "2022   10.0800\n",
      "Name: dividend, dtype: float64\n",
      "近五年指數平均股息率:  7.21\n",
      "近 5 年 PR 指數累計報酬:  143.13\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.44223876]\n",
      "近 5 年 TR 指數累計報酬:  198.86\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.74987709]\n",
      "近 8 年 TR 指數累計報酬:  294.3\n",
      "近 8 年 加權 PR 指數累計報酬:  [2.21310936]\n",
      "前5檔最大總和權重 2023-03-01 00:00:00 0.2137\n",
      "44.664641622409036\n",
      "50 200 40 0.475 0.4\n",
      "最小檔數:  64\n",
      "取得再平衡股票清單...\n",
      "使用再平衡清單回測 Total Return...\n",
      "績效評核 - TR...\n",
      "beta: 1.02\n",
      "alpha TR: 4.40%\n",
      "計算 股數殖利率...\n",
      "平均年化周轉率:  162.58\n",
      "平均每年殖利率 6.96\n",
      "計算PR殖利率...\n",
      "近五年指數股息率: \n",
      "year\n",
      "2018    6.4700\n",
      "2019    7.4600\n",
      "2020    8.3400\n",
      "2021    6.9100\n",
      "2022   11.4300\n",
      "Name: dividend, dtype: float64\n",
      "近五年指數平均股息率:  8.12\n",
      "近 5 年 PR 指數累計報酬:  141.38\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.44223876]\n",
      "近 5 年 TR 指數累計報酬:  204.94\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.74987709]\n",
      "近 8 年 TR 指數累計報酬:  323.08\n",
      "近 8 年 加權 PR 指數累計報酬:  [2.21310936]\n",
      "前5檔最大總和權重 2023-03-01 00:00:00 0.3149\n",
      "36.59736782106881\n",
      "50 250 40 0.475 0.4\n",
      "最小檔數:  72\n",
      "取得再平衡股票清單...\n",
      "使用再平衡清單回測 Total Return...\n",
      "績效評核 - TR...\n",
      "beta: 1.02\n",
      "alpha TR: 4.25%\n",
      "計算 股數殖利率...\n",
      "平均年化周轉率:  166.5\n",
      "平均每年殖利率 7.34\n",
      "計算PR殖利率...\n",
      "近五年指數股息率: \n",
      "year\n",
      "2018    6.5800\n",
      "2019    7.9200\n",
      "2020    8.5600\n",
      "2021    7.2400\n",
      "2022   12.2000\n",
      "Name: dividend, dtype: float64\n",
      "近五年指數平均股息率:  8.5\n",
      "近 5 年 PR 指數累計報酬:  128.34\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.44223876]\n",
      "近 5 年 TR 指數累計報酬:  190.17\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.74987709]\n",
      "近 8 年 TR 指數累計報酬:  298.71\n",
      "近 8 年 加權 PR 指數累計報酬:  [2.21310936]\n",
      "前5檔最大總和權重 2023-03-01 00:00:00 0.3103\n",
      "25.785630474983677\n",
      "50 200 40 0.475 0.35\n",
      "最小檔數:  64\n",
      "取得再平衡股票清單...\n",
      "使用再平衡清單回測 Total Return...\n",
      "績效評核 - TR...\n",
      "beta: 1.02\n",
      "alpha TR: 4.13%\n",
      "計算 股數殖利率...\n",
      "平均年化周轉率:  154.55\n",
      "平均每年殖利率 6.81\n",
      "計算PR殖利率...\n",
      "近五年指數股息率: \n",
      "year\n",
      "2018    6.3300\n",
      "2019    7.3500\n",
      "2020    8.1400\n",
      "2021    6.7300\n",
      "2022   11.1800\n",
      "Name: dividend, dtype: float64\n",
      "近五年指數平均股息率:  7.95\n",
      "近 5 年 PR 指數累計報酬:  141.27\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.44223876]\n",
      "近 5 年 TR 指數累計報酬:  203.26\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.74987709]\n",
      "近 8 年 TR 指數累計報酬:  317.62\n",
      "近 8 年 加權 PR 指數累計報酬:  [2.21310936]\n",
      "前5檔最大總和權重 2023-03-01 00:00:00 0.3014\n",
      "38.643698973591015\n",
      "50 250 40 0.475 0.35\n",
      "最小檔數:  72\n",
      "取得再平衡股票清單...\n",
      "使用再平衡清單回測 Total Return...\n",
      "績效評核 - TR...\n",
      "beta: 1.02\n",
      "alpha TR: 4.08%\n",
      "計算 股數殖利率...\n",
      "平均年化周轉率:  157.75\n",
      "平均每年殖利率 7.19\n",
      "計算PR殖利率...\n",
      "近五年指數股息率: \n",
      "year\n",
      "2018    6.4800\n",
      "2019    7.8100\n",
      "2020    8.3600\n",
      "2021    7.1100\n",
      "2022   11.9300\n",
      "Name: dividend, dtype: float64\n",
      "近五年指數平均股息率:  8.34\n",
      "近 5 年 PR 指數累計報酬:  130.14\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.44223876]\n",
      "近 5 年 TR 指數累計報酬:  191.28\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.74987709]\n",
      "近 8 年 TR 指數累計報酬:  298.25\n",
      "近 8 年 加權 PR 指數累計報酬:  [2.21310936]\n",
      "前5檔最大總和權重 2023-03-01 00:00:00 0.2968\n",
      "27.233407403467215\n",
      "50 200 40 0.475 0.3\n",
      "最小檔數:  64\n",
      "取得再平衡股票清單...\n",
      "使用再平衡清單回測 Total Return...\n",
      "績效評核 - TR...\n",
      "beta: 1.02\n",
      "alpha TR: 3.86%\n",
      "計算 股數殖利率...\n",
      "平均年化周轉率:  146.59\n",
      "平均每年殖利率 6.66\n",
      "計算PR殖利率...\n",
      "近五年指數股息率: \n",
      "year\n",
      "2018    6.2000\n",
      "2019    7.2500\n",
      "2020    7.9300\n",
      "2021    6.5500\n",
      "2022   10.9300\n",
      "Name: dividend, dtype: float64\n",
      "近五年指數平均股息率:  7.77\n",
      "近 5 年 PR 指數累計報酬:  141.16\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.44223876]\n",
      "近 5 年 TR 指數累計報酬:  201.58\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.74987709]\n",
      "近 8 年 TR 指數累計報酬:  312.23\n",
      "近 8 年 加權 PR 指數累計報酬:  [2.21310936]\n",
      "前5檔最大總和權重 2023-03-01 00:00:00 0.2883\n",
      "40.929211689395025\n",
      "50 250 40 0.475 0.3\n",
      "最小檔數:  72\n",
      "取得再平衡股票清單...\n",
      "使用再平衡清單回測 Total Return...\n",
      "績效評核 - TR...\n",
      "beta: 1.02\n",
      "alpha TR: 3.90%\n",
      "計算 股數殖利率...\n",
      "平均年化周轉率:  149.1\n",
      "平均每年殖利率 7.04\n",
      "計算PR殖利率...\n",
      "近五年指數股息率: \n",
      "year\n",
      "2018    6.3900\n",
      "2019    7.7000\n",
      "2020    8.1600\n",
      "2021    6.9800\n",
      "2022   11.6700\n",
      "Name: dividend, dtype: float64\n",
      "近五年指數平均股息率:  8.18\n",
      "近 5 年 PR 指數累計報酬:  131.96\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.44223876]\n",
      "近 5 年 TR 指數累計報酬:  192.38\n",
      "近 5 年 加權 PR 指數累計報酬:  [1.74987709]\n",
      "近 8 年 TR 指數累計報酬:  297.77\n",
      "近 8 年 加權 PR 指數累計報酬:  [2.21310936]\n",
      "前5檔最大總和權重 2023-03-01 00:00:00 0.2833\n",
      "28.850405011903373\n"
     ]
    }
   ],
   "source": [
    "CAP_TOP_options = [50]\n",
    "CAP_BOT_options = [200, 250]\n",
    "AMOUNT_FLOOR_options = [50]\n",
    "N_options = [40, 50]\n",
    "\n",
    "TILTED_NUM_options = [0, 0.1 , 0.2, 0.3, 0.4]\n",
    "TILTED_options = [0, 0.1 , 0.2, 0.3, 0.4]\n",
    "\n",
    "NUM_CUT = 5\n",
    "result_lst = []\n",
    "num_greed = 0\n",
    "\n",
    "TURNOVER_DICT = {\n",
    "    '2': 10,\n",
    "    '3': 10,\n",
    "    '5': 30,\n",
    "    '7': 30,\n",
    "    '11': 10,\n",
    "}\n",
    "\n",
    "WEIGHT_BY_YIELDS = False\n",
    "\n",
    "FACTOR_WEIGHT = 1\n",
    "LDY_WEIGHT = 1\n",
    "D1Y_WEIGHT = 1\n",
    "AMOUNT_FLOOR = 50\n",
    "\n",
    "\n",
    "# Use itertools.product() to iterate through each combination\n",
    "for CAP_TOP, CAP_BOT, N, TILTED_NUM, TILTED in [[50, 200, 40, 0, 0], [50, 250, 40, 0, 0], [50, 200, 40, 0.475, 0.4], [50, 250, 40, 0.475, 0.4], [50, 200, 40, 0.475, 0.35], [50, 250, 40, 0.475, 0.35], [50, 200, 40, 0.475, 0.3], [50, 250, 40, 0.475, 0.3]]:\n",
    "    print(CAP_TOP, CAP_BOT, N, TILTED_NUM, TILTED)\n",
    "    # concat the params with \"_\" for filename prefix\n",
    "    params_prefix = '_'.join([str(CAP_TOP), str(CAP_BOT), str(N), str(TILTED_NUM), str(TILTED)])\n",
    "\n",
    "    ADJUST_WEIGHTS_PARAMS = {\n",
    "    \"adjust_type\": ['triangle','triangle'], \n",
    "    \"ratio\": TILTED_NUM, \n",
    "    \"weight_ratio\": TILTED, \n",
    "    \"rank_col\": 'rank_sum_average_rank', \n",
    "    \"weight_col\": 'weight'\n",
    "    }\n",
    "\n",
    "\n",
    "    df_sample_pool = df_factor_all_reb[(df_factor_all_reb[\"market_cap_rank\"] > CAP_TOP) & (df_factor_all_reb[\"market_cap_rank\"] <= CAP_BOT)].copy()\n",
    "\n",
    "    df_sample_pool['roe_rank'] = df_sample_pool.groupby('date')['roe'].rank(ascending=False)\n",
    "    df_sample_pool['roe_rank_qcut'] = df_sample_pool.groupby('date', group_keys=False)['roe_rank'].apply(lambda x: pd.qcut(x, NUM_CUT, labels=False, duplicates=\"drop\"))\n",
    "\n",
    "    df_sample_pool['20_d_return_rank'] = df_sample_pool.groupby('date')['20_d_return'].rank(ascending=False)\n",
    "    df_sample_pool['40_d_return_rank'] = df_sample_pool.groupby('date')['40_d_return'].rank(ascending=False)\n",
    "    df_sample_pool['60_d_return_rank'] = df_sample_pool.groupby('date')['60_d_return'].rank(ascending=False)\n",
    "    df_sample_pool['tobins_q_rank'] = df_sample_pool.groupby('date')['tobins_q'].rank(ascending=False)\n",
    "    df_sample_pool['roe_4q_sum_rank'] = df_sample_pool.groupby('date')['roe_4q_sum'].rank(ascending=False)\n",
    "    df_sample_pool['ni_yoy_rank'] = df_sample_pool.groupby('date')['ni_yoy'].rank(ascending=False)\n",
    "    df_sample_pool['ni_qoq_rank'] = df_sample_pool.groupby('date')['ni_qoq'].rank(ascending=False)\n",
    "\n",
    "    df_sample_pool['ni_yoy_rank_qcut'] = df_sample_pool.groupby('date', group_keys=False)['ni_yoy_rank'].apply(lambda x: pd.qcut(x, NUM_CUT, labels=False, duplicates=\"drop\"))\n",
    "\n",
    "    df_sample_pool['meeting_last_year_yield'] = np.where(df_sample_pool['last_dividend_yield'] == 0, df_sample_pool['dividend_1Y_sum_yield'], df_sample_pool['last_dividend_yield'])\n",
    "    df_sample_pool['last_dividend_yield_rank'] = df_sample_pool.groupby('date')['last_dividend_yield'].rank(ascending=False)\n",
    "    df_sample_pool['dividend_1Y_sum_yield_rank'] = df_sample_pool.groupby('date')['dividend_1Y_sum_yield'].rank(ascending=False)\n",
    "    # df_sample_pool['roe_rank_qcut'] = df_sample_pool.groupby('date', group_keys=False)['roe_rank'].apply(lambda x: pd.qcut(x, NUM_CUT, labels=False, duplicates=\"drop\"))\n",
    "    df_sample_pool['ocf / asset_rank'] = df_sample_pool.groupby('date')['ocf / asset'].rank(ascending=False)\n",
    "    df_sample_pool['ocf / asset_rank_qcut'] = df_sample_pool.groupby('date', group_keys=False)['ocf / asset_rank'].apply(lambda x: pd.qcut(x, NUM_CUT, labels=False, duplicates=\"drop\"))\n",
    "\n",
    "    df_sample_pool['rank_sum_1'] = df_sample_pool['roe_rank']\n",
    "    df_sample_pool['rank_sum_1_rank'] = df_sample_pool.groupby('date')['rank_sum_1'].rank(ascending=True)\n",
    "    df_sample_pool['rank_sum_1_rank_qcut'] = df_sample_pool.groupby('date', group_keys=False)['rank_sum_1_rank'].apply(lambda x: pd.qcut(x, NUM_CUT, labels=False, duplicates=\"drop\"))\n",
    "\n",
    "    df_sample_pool['rank_sum_2'] = df_sample_pool['roe_rank'] + df_sample_pool['60_d_return_rank']\n",
    "    df_sample_pool['rank_sum_2_rank'] = df_sample_pool.groupby('date')['rank_sum_2'].rank(ascending=True)\n",
    "    df_sample_pool['rank_sum_2_rank_qcut'] = df_sample_pool.groupby('date', group_keys=False)['rank_sum_2_rank'].apply(lambda x: pd.qcut(x, NUM_CUT, labels=False, duplicates=\"drop\"))\n",
    "\n",
    "    # df_sample_pool['rank_sum_3'] = df_sample_pool['roe_rank'] + df_sample_pool['60_d_return_rank'] + df_sample_pool['ni_yoy_rank'] + df_sample_pool['ni_qoq_rank']\n",
    "    # df_sample_pool['rank_sum_3'] = df_sample_pool['roe_rank'] + df_sample_pool['60_d_return_rank'] + df_sample_pool['ni_qoq_rank']\n",
    "    df_sample_pool['rank_sum_3'] = df_sample_pool['roe_rank'] + df_sample_pool['60_d_return_rank'] + df_sample_pool['ni_qoq_rank']\n",
    "    df_sample_pool['rank_sum_3_rank'] = df_sample_pool.groupby('date')['rank_sum_3'].rank(ascending=True)\n",
    "    df_sample_pool['rank_sum_3_rank_qcut'] = df_sample_pool.groupby('date', group_keys=False)['rank_sum_3_rank'].apply(lambda x: pd.qcut(x, NUM_CUT, labels=False, duplicates=\"drop\"))\n",
    "\n",
    "    df_sample_pool['rank_sum_average'] = df_sample_pool['rank_sum_3_rank'] * FACTOR_WEIGHT + df_sample_pool['last_dividend_yield_rank'] * LDY_WEIGHT + df_sample_pool['dividend_1Y_sum_yield_rank'] * D1Y_WEIGHT\n",
    "\n",
    "    # ---------------------------------------------- 設定流動性篩選 ----------------------------------------------\n",
    "\n",
    "    df_temp = pd.merge(df_sample_pool, df_price_sub, how=\"left\", on=[\"date\", \"ticker\"])\n",
    "    df_temp = pd.merge(df_temp, df_factor_all_amount_rank[['date','ticker','amount_rank_20']], how = 'left', on = ['date','ticker'])\n",
    "    df_temp = df_temp.dropna()\n",
    "\n",
    "    df_temp['cond1'] = df_temp['amount_rank_20'] < 0.25\n",
    "    df_temp['cond2'] = df_temp['20_d_mean_amount_k'] > AMOUNT_FLOOR * 1000\n",
    "    df_temp['cond3'] = df_temp['60_d_median_amount_k'] > AMOUNT_FLOOR * 1000\n",
    "    df_temp['cond4'] = df_temp['20_d_median_amount_k'] > AMOUNT_FLOOR * 1000\n",
    "    df_temp['cond5'] = df_temp['20_d_median_amount_k'] > AMOUNT_FLOOR * 1000\n",
    "    df_temp['cond6'] = df_temp['60_d_median_amount_k'] > AMOUNT_FLOOR * 1000\n",
    "\n",
    "    df_liq_pool = df_temp[(df_temp['cond5'] == True) & (df_temp['cond3'] == True) & (df_temp['cond1'] == True)].copy()\n",
    "    df_liq_pool_for_exist = df_temp[(df_temp['cond6'] == True) & (df_temp['cond4'] == True) & (df_temp['cond1'] == True)].copy()\n",
    "\n",
    "    print(\"最小檔數: \", df_liq_pool.groupby('date')['ticker'].count().min())\n",
    "\n",
    "    # ---------------------------------------------- 取得再平衡股票清單 ----------------------------------------------\n",
    "    print('取得再平衡股票清單...')\n",
    "\n",
    "    df_factor_all = df_factor_all.dropna(subset=['rebalance_date']).copy()\n",
    "    reb_lst = df_factor_all['rebalance_date'].unique()\n",
    "\n",
    "    sort_column = 'rank_sum_average'\n",
    "    apply_restrict_index = 0\n",
    "    base_portfolio_number = N\n",
    "    restrict_turnover = 10 / 100\n",
    "    remain_number =  int(np.ceil(base_portfolio_number * (1 - restrict_turnover)))\n",
    "    # round up the restrict_portfolio_number\n",
    "    restrict_portfolio_number =  (base_portfolio_number * 2 - remain_number)\n",
    "    df_select_pool = df_liq_pool.reset_index(drop=True)\n",
    "    df_select_pool_for_exist = df_liq_pool_for_exist.reset_index(drop=True)\n",
    "    # get the base portfolio by base_portfolio_number \n",
    "    df_select_pool_base = df_select_pool.groupby('date').apply(top_n, n = base_portfolio_number, columns=[sort_column], ascending=[True]).reset_index(drop=True)\n",
    "    # get the restrict portfolio by restrict_portfolio_number\n",
    "    df_select_pool_restrict = df_select_pool\n",
    "    df_select_pool_restrict.reset_index(drop=True, inplace=True)\n",
    "    df_select_pool_restrict_for_exist = df_select_pool_for_exist.reset_index(drop=True)\n",
    "\n",
    "    apply_restrict_date = np.sort(reb_lst)[apply_restrict_index]\n",
    "    # string format\n",
    "    apply_restrict_date = pd.to_datetime(apply_restrict_date).strftime('%Y-%m-%d')\n",
    "\n",
    "    df_restrict_result = pd.DataFrame([])\n",
    "    # concat the data that date is smaller than apply_restrict_date to df_restrict_result\n",
    "    df_restrict_result = pd.concat([df_restrict_result, df_select_pool_base[df_select_pool_base['date'] < apply_restrict_date]], axis=0)\n",
    "    # print the max date in df_restrict_result\n",
    "\n",
    "    for i in range(apply_restrict_index, len(reb_lst)):\n",
    "        # get the month of reb_lst[i]\n",
    "        month = reb_lst[i].month\n",
    "\n",
    "        apply_restrict_index = 0\n",
    "        base_portfolio_number = N\n",
    "        restrict_turnover = TURNOVER_DICT[str(month)] / 100\n",
    "        remain_number =  int(np.ceil(base_portfolio_number * (1 - restrict_turnover)))\n",
    "        # round up the restrict_portfolio_number\n",
    "        restrict_portfolio_number =  (base_portfolio_number * 2 - remain_number)\n",
    "\n",
    "        # get the slice data by reb_lst[i] in df_select_pool_restrict\n",
    "        df_select_pool_restrict_temp = df_select_pool_restrict[df_select_pool_restrict['rebalance_date'] == reb_lst[i]].reset_index(drop=True)\n",
    "        df_select_pool_restrict_temp_for_exist = df_select_pool_restrict_for_exist[df_select_pool_restrict_for_exist['rebalance_date'] == reb_lst[i]].reset_index(drop=True)\n",
    "\n",
    "        # get the slice data by reb_lst[i-1] in df_restrict_result, [i-1] is because we need to get the last portfolio\n",
    "        df_restrict_result_temp = df_restrict_result[df_restrict_result['rebalance_date'] == reb_lst[i - 1]].reset_index(drop=True)\n",
    "\n",
    "        # prepare the dataframe for finding the joint ticker\n",
    "        df_new_temp = df_select_pool_restrict_temp[['date','ticker',sort_column, 'dividend_1Y_sum_yield']].copy()\n",
    "        df_new_temp['restrict'] = 1\n",
    "        df_new_temp.sort_values([sort_column,'dividend_1Y_sum_yield'], ascending=True, inplace=True)\n",
    "        df_new_temp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        last_portfolio_ticker_list = df_restrict_result_temp['ticker'].unique()\n",
    "\n",
    "        # df_priority_temp = df_select_pool_restrict_temp[df_select_pool_restrict_temp['ticker'].isin(last_portfolio_ticker_list)].copy()\n",
    "        df_priority_temp = df_select_pool_restrict_temp_for_exist[df_select_pool_restrict_temp_for_exist['ticker'].isin(last_portfolio_ticker_list)].copy()\n",
    "        df_priority_temp.sort_values([sort_column,'dividend_1Y_sum_yield'], ascending=True, inplace=True)\n",
    "        df_priority_temp.reset_index(drop=True, inplace=True)\n",
    "        df_priority = df_priority_temp.head(remain_number)\n",
    "\n",
    "        df_added = df_new_temp[df_new_temp['ticker'].isin(df_priority['ticker'].unique()) == False].head(base_portfolio_number - len(df_priority)).reset_index(drop=True)\n",
    "        df_triviality = df_select_pool_restrict_temp[df_select_pool_restrict_temp['ticker'].isin(df_added['ticker'].unique())].reset_index(drop=True)\n",
    "\n",
    "        df_restrict_result_temp = pd.concat([df_priority, df_triviality], axis=0)\n",
    "\n",
    "        # concat the df_restrict_result_temp to df_restrict_result\n",
    "        df_restrict_result = pd.concat([df_restrict_result, df_restrict_result_temp], axis=0)\n",
    "\n",
    "\n",
    "    df_restrict_result.reset_index(drop=True, inplace=True)\n",
    "    # df_restrict_result_return = df_restrict_result.groupby('date')['y'].mean()\n",
    "    df_restrict_result_return = df_restrict_result.groupby('date')['rebalance_period_return'].mean()\n",
    "    df_restrict_result['rank_sum_average_rank'] = df_restrict_result.groupby('date')['rank_sum_average'].rank(ascending=True)\n",
    "\n",
    "    # ---------------------------------------------- 使用再平衡清單回測 - TR ----------------------------------------------\n",
    "    print('使用再平衡清單回測 Total Return...')\n",
    "\n",
    "    df_adjusted_price_for_backtest = df_adjusted_price.copy()\n",
    "    df_adjusted_price_for_backtest.columns = ['date','ticker','price']\n",
    "\n",
    "    (df_portfolio_value_all, \n",
    "    df_portfolio_value_detail_start, \n",
    "    df_portfolio_value_detail_end, \n",
    "    df_portfolio_value_detail_all\n",
    "    ) = get_daily_portfolio(df_restrict_result, reb_lst, df_adjusted_price_for_backtest, 'vw', **ADJUST_WEIGHTS_PARAMS, weight_by_yields = WEIGHT_BY_YIELDS, replace_bottom='min')\n",
    "\n",
    "    df_portfolio_value_all.reset_index(drop = True).to_feather(f'./data/quant/backtest/{params_prefix}_portfolio_value_all.feather')\n",
    "    df_portfolio_value_detail_start.reset_index(drop = True).to_feather(f'./data/quant/backtest/{params_prefix}_portfolio_value_detail_start.feather')\n",
    "    df_portfolio_value_detail_end.reset_index(drop = True).to_feather(f'./data/quant/backtest/{params_prefix}_portfolio_value_detail_end.feather')\n",
    "    df_portfolio_value_detail_all.reset_index(drop = True).to_feather(f'./data/quant/backtest/{params_prefix}_portfolio_value_detail_all.feather')\n",
    "\n",
    "\n",
    "    df_compare_portfolio = df_portfolio_value_all.copy()\n",
    "    df_compare_portfolio.columns = ['date','portfolio_value']\n",
    "\n",
    "    # ---------------------------------------------- 績效評核 - TR ----------------------------------------------\n",
    "    print('績效評核 - TR...')\n",
    "\n",
    "    df_benchmarks_all = pd.read_excel('./data/benchmarks.xlsx')\n",
    "    df_benchmarks_all.columns = ['日期', 'TWA02', 'TWA00']\n",
    "    benchmark_list = df_benchmarks_all.columns.to_list()\n",
    "    benchmark_list.remove('日期')\n",
    "\n",
    "    index_name = benchmark_list[0]\n",
    "    df_benchmarks_temp = df_benchmarks_all[['日期',f'{index_name}']].copy()\n",
    "    df_benchmarks_temp.columns = ['date',f'{index_name}']\n",
    "    df_benchmarks_temp.dropna(inplace=True)\n",
    "    # change the date format to datetime\n",
    "    df_benchmarks_temp['date'] = pd.to_datetime(df_benchmarks_temp['date'], format='%Y/%m/%d')\n",
    "    df_benchmarks_temp.sort_values('date', inplace=True)\n",
    "    df_benchmarks = df_benchmarks_temp.merge(df_compare_portfolio, on='date', how='left').dropna().copy()\n",
    "    df_benchmarks.reset_index(drop=True, inplace=True)\n",
    "    df_benchmarks.drop_duplicates(inplace=True)\n",
    "\n",
    "    # df_benchmarks = df_benchmarks[df_benchmarks['date']> '2018-08-01']\n",
    "    # scale the benchmark and portfolio value to 1\n",
    "    df_benchmarks[f'{index_name}_scale'] = df_benchmarks[f'{index_name}'] / df_benchmarks[f'{index_name}'].iloc[0]\n",
    "    df_benchmarks['portfolio_value_scale'] = df_benchmarks['portfolio_value'] / df_benchmarks['portfolio_value'].iloc[0]\n",
    "\n",
    "    df_benchmarks.set_index('date', inplace=True)\n",
    "\n",
    "    df_benchmarks['portfolio_value_rt'] = df_benchmarks['portfolio_value_scale'].pct_change()\n",
    "    df_benchmarks[f'{index_name}_rt'] = df_benchmarks[f'{index_name}_scale'].pct_change()\n",
    "\n",
    "    # save the df_benchmarks to feather\n",
    "    df_benchmarks.to_excel(f'./data/quant/backtest/{params_prefix}_df_benchmarks.xlsx')\n",
    "\n",
    "    # calculate the beta of portfolio and benchmark\n",
    "    beta = df_benchmarks[['portfolio_value_rt', f'{index_name}_rt']].cov().iloc[0,1] / df_benchmarks[f'{index_name}_rt'].var()\n",
    "    print(f'beta: {beta:.2f}')\n",
    "\n",
    "    # calculate the alpha of portfolio and benchmark\n",
    "    alpha = df_benchmarks[['portfolio_value_rt', f'{index_name}_rt']].mean().iloc[0] - beta * df_benchmarks[f'{index_name}_rt'].mean()\n",
    "    # annualized the alpha\n",
    "    ann_alpha = (1 + alpha) ** 252 - 1\n",
    "    print(f'alpha TR: {ann_alpha:.2%}')\n",
    "\n",
    "    df_benchmarks['year'] = df_benchmarks.index.year\n",
    "    df_benchmarks['month'] = df_benchmarks.index.month\n",
    "    df_benchmarks['quarter'] = df_benchmarks.index.quarter\n",
    "\n",
    "    last_values = df_benchmarks.groupby(['year','month']).tail(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "    first_values  = df_benchmarks.groupby(['year','month']).head(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "    df_monthly_return = pd.DataFrame(last_values / first_values)\n",
    "\n",
    "    df_monthly_return.columns = [f'{index_name}','portfolio_value_scale']\n",
    "    # drop the last row\n",
    "    df_monthly_return = df_monthly_return[:-1]\n",
    "    df_monthly_return['win_rate'] = np.where(df_monthly_return['portfolio_value_scale'] > df_monthly_return[f'{index_name}'], 1, 0)\n",
    "\n",
    "    df_monthly_return['portfolio_rt'] = df_monthly_return['portfolio_value_scale'].pct_change()\n",
    "    df_monthly_return[f'{index_name}_rt'] = df_monthly_return[f'{index_name}'].pct_change()\n",
    "    last_values = df_benchmarks.groupby(['year','month']).tail(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "    first_values  = df_benchmarks.groupby(['year','month']).head(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "\n",
    "    df_quarterly_return = pd.DataFrame(last_values / first_values)\n",
    "    df_quarterly_return.columns = [f'{index_name}','portfolio_value_scale']\n",
    "    df_quarterly_return['win_rate'] = np.where(df_quarterly_return['portfolio_value_scale'] > df_quarterly_return[f'{index_name}'], 1, 0)\n",
    "    last_values = df_benchmarks.groupby(['year']).tail(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "    first_values  = df_benchmarks.groupby(['year']).head(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "    df_yearly_return = pd.DataFrame(last_values / first_values)\n",
    "    df_yearly_return.columns = [f'{index_name}','portfolio_value_scale']\n",
    "\n",
    "    df_yearly_return['win_rate'] = np.where(df_yearly_return['portfolio_value_scale'] > df_yearly_return[f'{index_name}'], 1, 0)\n",
    "    # create a list from 2005 to 2023 for year column for df_yearly_return\n",
    "    year_list = list(range(2005,2024))\n",
    "    df_yearly_return['year'] = year_list\n",
    "\n",
    "    df_yearly_return[['portfolio_value_scale',f'{index_name}']] = df_yearly_return[['portfolio_value_scale',f'{index_name}']] - 1\n",
    "\n",
    "    df_benchmarks_temp.reset_index(inplace=True, drop=True)\n",
    "    df_benchmarks_temp.set_index('date', inplace=True)\n",
    "\n",
    "\n",
    "    # series_cagr = calculate_cagr(df_benchmarks[df_benchmarks.index > '2007-06-21'])[:3]\n",
    "    series_cagr = calculate_cagr(df_benchmarks)[:2]\n",
    "    series_sr = calc_sharpe_ratio(df_benchmarks)[:2]\n",
    "\n",
    "\n",
    "    # ---------------------------------------------- 計算 股數殖利率 ----------------------------------------------\n",
    "    print('計算 股數殖利率...')\n",
    "\n",
    "    select_ticker = df_restrict_result['ticker'].unique()\n",
    "    df_cash_dividends = pd.read_feather('data/tej_cash_dividends.feather')\n",
    "    df_cash_dividends = ut.tej_data_clean_up(df_cash_dividends)\n",
    "    df_cash_dividends = df_cash_dividends[['股票代號','除息日','息值(元)']].copy()\n",
    "    df_cash_dividends.columns = ['ticker','date','dividend']\n",
    "    df_cash_dividends = df_cash_dividends[df_cash_dividends['ticker'].isin(select_ticker)].copy()\n",
    "    df_cash_dividends.drop_duplicates(inplace=True)\n",
    "    df_cash_dividends['dividend'] = df_cash_dividends['dividend'].astype(float)\n",
    "    df_cash_dividends = df_cash_dividends.groupby(['ticker','date']).sum().reset_index()\n",
    "\n",
    "    df_factor_all_price = pd.merge(df_factor_all_select,df_price_div,on=['date','ticker'],how='left')\n",
    "    df_factor_all_price_dividend = pd.merge(df_factor_all_price,df_cash_dividends,on=['date','ticker'],how='left')\n",
    "    df_factor_all_price_dividend['unadj_yield'] = df_factor_all_price_dividend['dividend'] / df_factor_all_price_dividend['yesterday_price']\n",
    "\n",
    "    # calculate the sum of dividend yield of each stock in each period \n",
    "    df_period_yield = df_factor_all_price_dividend.groupby(['ticker','rebalance_date'], as_index=False, group_keys=False)['unadj_yield'].sum()\n",
    "\n",
    "    # merge the sum of dividend yield to df_dividend_select for calculate the portfolio dividend yield\n",
    "    df_dividend_select_yield = pd.merge(df_restrict_result,df_period_yield,on=['ticker','rebalance_date'],how='left')\n",
    "\n",
    "    # create the weight column for each ticker, weight = 1 / total num of ticker in the rebalance date\n",
    "    df_dividend_select_yield['weight'] = 1 / df_dividend_select_yield.groupby('rebalance_date')['ticker'].transform('count')\n",
    "\n",
    "    turnover_ratio_lst =  []\n",
    "\n",
    "    for i in range(1, len(reb_lst) - 1):\n",
    "        df_start_temp = df_portfolio_value_detail_start[df_portfolio_value_detail_start['date'].isin([reb_lst[i]])]\n",
    "        df_end_temp = df_portfolio_value_detail_end[df_portfolio_value_detail_end['date'].isin([reb_lst[i]])]\n",
    "        df_rebalance_temp = pd.merge(df_start_temp, df_end_temp, on=['date','ticker'], how='outer', suffixes=('_start', '_end')).fillna(0)\n",
    "        df_rebalance_temp['turnover'] = abs(df_rebalance_temp['value_end'] - df_rebalance_temp['value_start'])\n",
    "        turnover_ratio = (df_rebalance_temp['turnover'].sum() / df_start_temp['value'].sum()) / 2 * 100\n",
    "        turnover_ratio_lst.append(turnover_ratio)\n",
    "\n",
    "    # create a dataframe to store the turnover ratio with the rebalance date\n",
    "    df_quarterly_turnover = pd.DataFrame({'date': reb_lst[1:-1], 'turnover': turnover_ratio_lst}).dropna()\n",
    "\n",
    "    df_quarterly_turnover['year'] = df_quarterly_turnover['date'].dt.year\n",
    "    df_quarterly_turnover['quarter'] = df_quarterly_turnover['date'].dt.quarter\n",
    "    df_yearly_turnover = (df_quarterly_turnover.groupby('year')['turnover'].mean() * 4).reset_index()\n",
    "\n",
    "    print(\"平均年化周轉率: \", df_yearly_turnover['turnover'].mean().round(2))\n",
    "    # df_yearly_turnover = df_quarterly_turnover.groupby('quarter')['turnover'].mean().reset_index()\n",
    "    df_turnover = df_yearly_turnover['turnover'].describe().reset_index()\n",
    "    df_turnover.columns = ['index_name', '一般版']\n",
    "\n",
    "    df_dividend_select_yield_test = df_dividend_select_yield.copy()\n",
    "    df_dividend_select_yield_test = ut.adjust_weights(df_dividend_select_yield_test, **ADJUST_WEIGHTS_PARAMS)\n",
    "\n",
    "    if WEIGHT_BY_YIELDS:\n",
    "        df_dividend_select_yield_test = ut.weight_by_yields(df_dividend_select_yield_test, 5, 'adjusted_weight')\n",
    "        use_weight = 'weight_by_yields'\n",
    "    else:\n",
    "        use_weight = 'adjusted_weight'\n",
    "\n",
    "\n",
    "    df_dividend_select_yield_test['weighted_yield'] = df_dividend_select_yield_test['unadj_yield'] * df_dividend_select_yield_test[use_weight]\n",
    "\n",
    "    df_weighted_dividends = df_dividend_select_yield_test[df_dividend_select_yield_test['weighted_yield'] > 0] [['date','ticker', use_weight,'weighted_yield']].copy()\n",
    "\n",
    "    df_quarterly_div = df_dividend_select_yield_test.groupby('date')['weighted_yield'].sum().reset_index()\n",
    "    df_quarterly_div['year'] = df_quarterly_div['date'].dt.year\n",
    "    print(\"平均每年殖利率\", round(df_quarterly_div.groupby('year')['weighted_yield'].sum().mean().round(4) * 100, 2))\n",
    "\n",
    "    df_quarterly_div.groupby('year')['weighted_yield'].sum().reset_index().to_excel(f'./data/quant/backtest/殖利率_{params_prefix}.xlsx', index=False)\n",
    "    # ---------------------------------------------- 計算PR殖利率 ----------------------------------------------\n",
    "    print('計算PR殖利率...')\n",
    "\n",
    "    df_reb_map = pd.DataFrame([])\n",
    "    df_reb_map['date'] = df_portfolio_value_detail_start['date'].unique()\n",
    "    df_reb_map['date_end'] = df_portfolio_value_detail_end['date'].unique()\n",
    "\n",
    "    df_dividends_value = pd.merge(df_weighted_dividends, df_benchmarks.reset_index()[['date','portfolio_value']])\n",
    "    df_dividends_value['dividends_value'] = df_dividends_value['portfolio_value'] * df_dividends_value['weighted_yield']\n",
    "\n",
    "    df_dividends_adjustment = pd.merge(df_portfolio_value_detail_start, df_dividends_value[['date','ticker','dividends_value']], how = 'left', on = ['date','ticker']).fillna(0)\n",
    "    total_value = df_dividends_adjustment.groupby('date')['value'].transform('sum')\n",
    "    df_dividends_adjustment['weight'] = df_dividends_adjustment['value'] / total_value\n",
    "    df_dividends_adjustment = pd.merge(df_dividends_adjustment, df_reb_map, on='date')\n",
    "    df_dividends_adjustment = pd.merge(df_dividends_adjustment, df_portfolio_value_detail_end, how = 'left', left_on = ['date_end','ticker'], right_on = ['date','ticker']).fillna(0)\n",
    "    # Compute the total value for each date\n",
    "\n",
    "    # Compute the weight of each ticker by dividing its value by the total value for its date\n",
    "    df_dividends_adjustment['last_value_ex_div'] = df_dividends_adjustment['value_y'] - df_dividends_adjustment['dividends_value']\n",
    "    df_dividends_adjustment['price_return'] = (df_dividends_adjustment['last_value_ex_div'] / df_dividends_adjustment['value_x'] - 1) * df_dividends_adjustment['weight']\n",
    "    df_dividends_adjustment['total_return'] = (df_dividends_adjustment['value_y'] / df_dividends_adjustment['value_x'] - 1) * df_dividends_adjustment['weight']\n",
    "    df_tr_pr = pd.merge(df_dividends_adjustment.groupby(['date_x'])['total_return'].sum().reset_index(), df_dividends_adjustment.groupby(['date_x'])['price_return'].sum(), on = 'date_x')\n",
    "    # change column name date_x to date\n",
    "    df_tr_pr = df_tr_pr.rename(columns={'date_x':'date'})\n",
    "\n",
    "    # add 1 to the return\n",
    "    df_tr_pr['total_return'] = df_tr_pr['total_return'] + 1\n",
    "    df_tr_pr['price_return'] = df_tr_pr['price_return'] + 1\n",
    "\n",
    "    # subtract year from date\n",
    "    df_tr_pr['year'] = df_tr_pr['date'].dt.year\n",
    "\n",
    "    # group by year and multiply the returns\n",
    "    df_tr_year = df_tr_pr.groupby('year')['total_return'].prod().reset_index()\n",
    "    df_pr_year = df_tr_pr.groupby('year')['price_return'].prod().reset_index()\n",
    "\n",
    "    # merge the two dataframes\n",
    "    df_tr_pr_year = pd.merge(df_tr_year, df_pr_year, on = 'year')\n",
    "    df_tr_pr_year['dividend'] = df_tr_pr_year['total_return'] - df_tr_pr_year['price_return']\n",
    "    df_tr_pr_year.index = df_tr_year['year']\n",
    "\n",
    "    df_tr_pr_year.to_excel(f'./data/quant/backtest/殖利率_{params_prefix}_指數.xlsx', index=False)\n",
    "\n",
    "    df_benchmarks_all = pd.read_excel('./data/benchmarks.xlsx')\n",
    "    df_benchmarks_all.columns = ['日期', 'TWA02', 'TWA00']\n",
    "\n",
    "    print(\"近五年指數股息率: \")\n",
    "    print(round(df_tr_pr_year['dividend'].tail(5) * 100, 2))\n",
    "    print(\"近五年指數平均股息率: \", round(df_tr_pr_year['dividend'].tail(5).mean() * 100, 2))\n",
    "    print(\"近 5 年 PR 指數累計報酬: \", round(df_tr_pr_year['price_return'].tail(5).prod() * 100, 2))\n",
    "    print(\"近 5 年 加權 PR 指數累計報酬: \", df_benchmarks_all[df_benchmarks_all['日期'] == '2023/03/01']['TWA00'].values / df_benchmarks_all[df_benchmarks_all['日期'] == '2018/02/27']['TWA00'].values)\n",
    "    print(\"近 5 年 TR 指數累計報酬: \", round(df_tr_pr_year['total_return'].tail(5).prod() * 100, 2))\n",
    "    print(\"近 5 年 加權 PR 指數累計報酬: \", df_benchmarks_all[df_benchmarks_all['日期'] == '2023/03/01']['TWA02'].values / df_benchmarks_all[df_benchmarks_all['日期'] == '2018/02/27']['TWA02'].values)\n",
    "    print(\"近 8 年 TR 指數累計報酬: \", round(df_tr_pr_year['total_return'].tail(8).prod() * 100, 2))\n",
    "    print(\"近 8 年 加權 PR 指數累計報酬: \", df_benchmarks_all[df_benchmarks_all['日期'] == '2023/03/01']['TWA02'].values / df_benchmarks_all[df_benchmarks_all['日期'] == '2015/02/26']['TWA02'].values)\n",
    "\n",
    "\n",
    "\n",
    "    df_quarterly_div['year'] = df_quarterly_div['date'].dt.year\n",
    "\n",
    "    mean_div = round(df_quarterly_div.groupby('year')['weighted_yield'].sum().mean() * 100, 2)\n",
    "\n",
    "    df_weight_detail = df_portfolio_value_detail_all.sort_values(['date','ticker']).reset_index(drop=True).copy()\n",
    "\n",
    "    # Compute the total value for each date\n",
    "    total_value = df_weight_detail.groupby('date')['value'].transform('sum')\n",
    "\n",
    "    # Compute the weight of each ticker by dividing its value by the total value for its date\n",
    "    df_weight_detail['weight'] = df_weight_detail['value'] / total_value\n",
    "\n",
    "    df_top_5_weighting = df_weight_detail.sort_values(['date','weight'], ascending = False).groupby('date').head(5).copy()\n",
    "    df_top_5_weighting = df_top_5_weighting.groupby('date')['weight'].sum().reset_index()\n",
    "    print(\"前5檔最大總和權重\",df_top_5_weighting.max()['date'], round(df_top_5_weighting.max()['weight'], 4))\n",
    "\n",
    "    df_market_cap_copy = df_factor_all[['date','ticker','market_cap']].copy()\n",
    "\n",
    "    df_weight_detail = pd.merge(df_weight_detail, df_market_cap_copy, on = ['date','ticker'], how = 'left').copy()\n",
    "\n",
    "    df_weight_detail['max_aum_assumption'] = df_weight_detail['market_cap'] * 0.1 / df_weight_detail['weight'] / 1000000\n",
    "\n",
    "    df_df_weight_detail_min = df_weight_detail[df_weight_detail['date'].isin(reb_lst) == False].groupby('date')['max_aum_assumption'].min().reset_index()\n",
    "    print(df_df_weight_detail_min[df_df_weight_detail_min['date'] > '2018-01-01'].min()['max_aum_assumption'])\n",
    "\n",
    "    df_normal_day = df_portfolio_value_detail_all[df_portfolio_value_detail_all['date'].isin(reb_lst) == False].sort_values(['date','ticker']).reset_index(drop = True).copy()\n",
    "    df_normal_day = df_normal_day[df_normal_day['date'] > '2018-01-01']\n",
    "    # Compute the total value for each date\n",
    "    total_value = df_normal_day.groupby('date')['value'].transform('sum')\n",
    "\n",
    "    # Compute the weight of each ticker by dividing its value by the total value for its date\n",
    "    df_normal_day['weight'] = df_normal_day['value'] / total_value\n",
    "    df_amount = df_price[['日期','股票代號','成交金額(千)']]\n",
    "    df_amount.columns = ['date','ticker','amount']\n",
    "\n",
    "    df_normal_day = pd.merge(df_normal_day, df_amount, how='left', on=['date', 'ticker']).dropna().reset_index(drop = True)\n",
    "    df_normal_day['amount'] = df_normal_day['amount'].astype(int)\n",
    "    df_normal_day = df_normal_day[df_normal_day['amount'] != 0]\n",
    "    df_normal_day['amount_assumption'] = df_normal_day['amount'] * 0.5 / df_normal_day['weight']\n",
    "    df_normal_day.sort_values(['date','amount_assumption'], inplace=True)\n",
    "    df_normal_day = df_normal_day.merge(df_factor_all_amount_rank[['date','ticker','amount_rank_20']], how='left', on=['date','ticker'])\n",
    "    df_normal_day.groupby('date')['amount_assumption'].min().mean()\n",
    "\n",
    "\n",
    "\n",
    "    # save the params and result to a dictionary\n",
    "    result_dict = {\n",
    "        'CAP_TOP': CAP_TOP,\n",
    "        'CAP_BOT': CAP_BOT,\n",
    "        'AMOUNT_FLOOR': AMOUNT_FLOOR,\n",
    "        'N': N,\n",
    "        'TILTED_NUM': TILTED_NUM,\n",
    "        'TILTED': TILTED,\n",
    "        'LDY_WEIGHT': LDY_WEIGHT,\n",
    "        'D1Y_WEIGHT': D1Y_WEIGHT,\n",
    "        'WEIGHT_BY_YIELDS': WEIGHT_BY_YIELDS,\n",
    "        'SR_BENCH': round(series_sr[0], 2),\n",
    "        'SR_PORT': round(series_sr[1], 2),\n",
    "        'CAGR_BENCH': round(series_cagr[0], 4),\n",
    "        'CAGR_PORT': round(series_cagr[1], 4),\n",
    "        'ALPHA': round(ann_alpha, 4),\n",
    "        'BETA': round(beta, 4),\n",
    "        'MEAN_DIV': round(mean_div, 4),\n",
    "        'TURNOVER(%)': round(df_turnover[df_turnover['index_name'] == 'mean']['一般版'].values[0], 2),\n",
    "        'PR_DIV_5Y': round(df_tr_pr_year['dividend'].tail(5).mean() * 100, 2),\n",
    "        'PR_DIV_ALL': round(df_tr_pr_year['dividend'].mean() * 100, 2),\n",
    "        'CUM_PR_PORT_5Y': round(df_tr_pr_year['price_return'].tail(5).prod() * 100, 2),\n",
    "        'CUM_PR_PORT_8Y': round(df_tr_pr_year['price_return'].prod() * 100, 2),\n",
    "        'CUM_TR_PORT_5Y': round(df_tr_pr_year['total_return'].tail(5).prod() * 100, 2),\n",
    "        'CUM_TR_PORT_8Y': round(df_tr_pr_year['total_return'].prod() * 100, 2),\n",
    "        'TOP_5_WEIGHTING': round(df_top_5_weighting.max()['weight'], 4),\n",
    "        'MIN_AUM_ASSUMPTION': df_df_weight_detail_min[df_df_weight_detail_min['date'] > '2018-01-01'].min()['max_aum_assumption'],\n",
    "        'MIN_AMOUNT_ASSUMPTION_MEAN': df_normal_day.groupby('date')['amount_assumption'].min().mean(),\n",
    "        'MIN_AMOUNT_ASSUMPTION_MIN': df_normal_day.groupby('date')['amount_assumption'].min().min(),\n",
    "    }\n",
    "    # concat the params with \"_\" for the json filename\n",
    "\n",
    "    # append the result_dict to result_lst\n",
    "    result_lst.append(result_dict)\n",
    "\n",
    "\n",
    "    # delete the variables to save memory\n",
    "    del df_benchmarks_all\n",
    "    del df_tr_pr_year\n",
    "    del df_quarterly_div\n",
    "    del df_weight_detail\n",
    "    del df_top_5_weighting\n",
    "    del df_market_cap_copy\n",
    "    del df_df_weight_detail_min\n",
    "    del df_turnover\n",
    "    del df_portfolio_value_detail_all\n",
    "    del df_portfolio_value_detail_start\n",
    "    del df_portfolio_value_detail_end\n",
    "    del df_cash_dividends\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    num_greed += 1\n",
    "\n",
    "df_greed = pd.DataFrame(result_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greed.to_excel('greed_params_1019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmarks_all = pd.read_excel('./data/benchmarks.xlsx')\n",
    "df_benchmarks_all.columns = ['日期', 'TWA02', 'TWA00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.971785228356077"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32229.2000 / 6482.4200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期</th>\n",
       "      <th>TWA02</th>\n",
       "      <th>TWA00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023/02/24</td>\n",
       "      <td>32229.2000</td>\n",
       "      <td>15503.7900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023/02/23</td>\n",
       "      <td>32461.2500</td>\n",
       "      <td>15615.4100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2023/02/22</td>\n",
       "      <td>32052.4700</td>\n",
       "      <td>15418.7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2023/02/21</td>\n",
       "      <td>32352.2800</td>\n",
       "      <td>15563.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2023/02/20</td>\n",
       "      <td>32327.8300</td>\n",
       "      <td>15551.2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5062</th>\n",
       "      <td>2003/01/08</td>\n",
       "      <td>4837.3500</td>\n",
       "      <td>4836.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5063</th>\n",
       "      <td>2003/01/07</td>\n",
       "      <td>4701.4800</td>\n",
       "      <td>4701.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5064</th>\n",
       "      <td>2003/01/06</td>\n",
       "      <td>4690.2600</td>\n",
       "      <td>4689.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5065</th>\n",
       "      <td>2003/01/03</td>\n",
       "      <td>4626.3600</td>\n",
       "      <td>4626.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5066</th>\n",
       "      <td>2003/01/02</td>\n",
       "      <td>4524.9200</td>\n",
       "      <td>4524.8700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4972 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              日期      TWA02      TWA00\n",
       "95    2023/02/24 32229.2000 15503.7900\n",
       "96    2023/02/23 32461.2500 15615.4100\n",
       "97    2023/02/22 32052.4700 15418.7700\n",
       "98    2023/02/21 32352.2800 15563.0000\n",
       "99    2023/02/20 32327.8300 15551.2300\n",
       "...          ...        ...        ...\n",
       "5062  2003/01/08  4837.3500  4836.9300\n",
       "5063  2003/01/07  4701.4800  4701.0800\n",
       "5064  2003/01/06  4690.2600  4689.8600\n",
       "5065  2003/01/03  4626.3600  4626.3200\n",
       "5066  2003/01/02  4524.9200  4524.8700\n",
       "\n",
       "[4972 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmarks_all[df_benchmarks_all['日期']< '2023/03/01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 日期 to datetime\n",
    "df_benchmarks_all['日期'] = pd.to_datetime(df_benchmarks_all['日期'], format='%Y/%m/%d')\n",
    "df_benchmarks_all['year'] = df_benchmarks_all['日期'].dt.year\n",
    "df_benchmarks_all = df_benchmarks_all.groupby('year').tail(1).sort_values('year').reset_index(drop=True)\n",
    "df_benchmarks_all['TWA00_rt'] = df_benchmarks_all['TWA00'].pct_change()\n",
    "df_benchmarks_all['TWA02_rt'] = df_benchmarks_all['TWA02'].pct_change()\n",
    "df_benchmarks_all['year']  = df_benchmarks_all['year'].shift(1)\n",
    "df_benchmarks_all = df_benchmarks_all[df_benchmarks_all['year'] >= 2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期</th>\n",
       "      <th>TWA02</th>\n",
       "      <th>TWA00</th>\n",
       "      <th>year</th>\n",
       "      <th>TWA00_rt</th>\n",
       "      <th>TWA02_rt</th>\n",
       "      <th>div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-02</td>\n",
       "      <td>7092.9900</td>\n",
       "      <td>6462.0600</td>\n",
       "      <td>2005.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.0423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>9055.4100</td>\n",
       "      <td>7920.8000</td>\n",
       "      <td>2006.0000</td>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.0509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>9845.4200</td>\n",
       "      <td>8323.0500</td>\n",
       "      <td>2007.0000</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.0365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>5862.1400</td>\n",
       "      <td>4698.3100</td>\n",
       "      <td>2008.0000</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.4046</td>\n",
       "      <td>0.0309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>10528.2600</td>\n",
       "      <td>8207.8500</td>\n",
       "      <td>2009.0000</td>\n",
       "      <td>0.7470</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.0490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>11998.7600</td>\n",
       "      <td>9025.3000</td>\n",
       "      <td>2010.0000</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>9618.1100</td>\n",
       "      <td>6952.2100</td>\n",
       "      <td>2011.0000</td>\n",
       "      <td>-0.2297</td>\n",
       "      <td>-0.1984</td>\n",
       "      <td>0.0313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>11164.5500</td>\n",
       "      <td>7779.2200</td>\n",
       "      <td>2012.0000</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.0418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>12724.7600</td>\n",
       "      <td>8612.5400</td>\n",
       "      <td>2013.0000</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>14121.9200</td>\n",
       "      <td>9274.1100</td>\n",
       "      <td>2014.0000</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>12844.3400</td>\n",
       "      <td>8114.2600</td>\n",
       "      <td>2015.0000</td>\n",
       "      <td>-0.1251</td>\n",
       "      <td>-0.0905</td>\n",
       "      <td>0.0346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>15288.1700</td>\n",
       "      <td>9272.8800</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.0475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>18351.0300</td>\n",
       "      <td>10710.7300</td>\n",
       "      <td>2017.0000</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.0453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>17045.4300</td>\n",
       "      <td>9554.1400</td>\n",
       "      <td>2018.0000</td>\n",
       "      <td>-0.1080</td>\n",
       "      <td>-0.0711</td>\n",
       "      <td>0.0368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>22566.0800</td>\n",
       "      <td>12100.4800</td>\n",
       "      <td>2019.0000</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.3239</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>28768.5700</td>\n",
       "      <td>14902.0300</td>\n",
       "      <td>2020.0000</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.0433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>36240.9600</td>\n",
       "      <td>18270.5100</td>\n",
       "      <td>2021.0000</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>29568.4700</td>\n",
       "      <td>14224.1200</td>\n",
       "      <td>2022.0000</td>\n",
       "      <td>-0.2215</td>\n",
       "      <td>-0.1841</td>\n",
       "      <td>0.0374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           日期      TWA02      TWA00      year  TWA00_rt  TWA02_rt    div\n",
       "3  2006-01-02  7092.9900  6462.0600 2005.0000    0.0519    0.0942 0.0423\n",
       "4  2007-01-02  9055.4100  7920.8000 2006.0000    0.2257    0.2767 0.0509\n",
       "5  2008-01-02  9845.4200  8323.0500 2007.0000    0.0508    0.0872 0.0365\n",
       "6  2009-01-05  5862.1400  4698.3100 2008.0000   -0.4355   -0.4046 0.0309\n",
       "7  2010-01-04 10528.2600  8207.8500 2009.0000    0.7470    0.7960 0.0490\n",
       "8  2011-01-03 11998.7600  9025.3000 2010.0000    0.0996    0.1397 0.0401\n",
       "9  2012-01-02  9618.1100  6952.2100 2011.0000   -0.2297   -0.1984 0.0313\n",
       "10 2013-01-02 11164.5500  7779.2200 2012.0000    0.1190    0.1608 0.0418\n",
       "11 2014-01-02 12724.7600  8612.5400 2013.0000    0.1071    0.1397 0.0326\n",
       "12 2015-01-05 14121.9200  9274.1100 2014.0000    0.0768    0.1098 0.0330\n",
       "13 2016-01-04 12844.3400  8114.2600 2015.0000   -0.1251   -0.0905 0.0346\n",
       "14 2017-01-03 15288.1700  9272.8800 2016.0000    0.1428    0.1903 0.0475\n",
       "15 2018-01-02 18351.0300 10710.7300 2017.0000    0.1551    0.2003 0.0453\n",
       "16 2019-01-02 17045.4300  9554.1400 2018.0000   -0.1080   -0.0711 0.0368\n",
       "17 2020-01-02 22566.0800 12100.4800 2019.0000    0.2665    0.3239 0.0574\n",
       "18 2021-01-04 28768.5700 14902.0300 2020.0000    0.2315    0.2749 0.0433\n",
       "19 2022-01-03 36240.9600 18270.5100 2021.0000    0.2260    0.2597 0.0337\n",
       "20 2023-01-03 29568.4700 14224.1200 2022.0000   -0.2215   -0.1841 0.0374"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmarks_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmarks_all['div'] = df_benchmarks_all['TWA02_rt'] - df_benchmarks_all['TWA00_rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040240577364224726"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmarks_all['div'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_tt = df_portfolio_value_detail_start[df_portfolio_value_detail_start['date'].isin(reb_lst)].groupby('date')['ticker'].count().reset_index()\n",
    "print(len(df_tt[df_tt['ticker'] <= 39]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocks Numbers Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>18.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>94.7222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>12.3339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25%</td>\n",
       "      <td>87.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50%</td>\n",
       "      <td>92.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75%</td>\n",
       "      <td>97.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max</td>\n",
       "      <td>130.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  turnover\n",
       "0  count   18.0000\n",
       "1   mean   94.7222\n",
       "2    std   12.3339\n",
       "3    min   80.0000\n",
       "4    25%   87.5000\n",
       "5    50%   92.5000\n",
       "6    75%   97.5000\n",
       "7    max  130.0000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the sum of dividend yield to df_dividend_select for calculate the portfolio dividend yield\n",
    "df_dividend_select_yield = pd.merge(df_restrict_result,df_period_yield,on=['ticker','rebalance_date'],how='left')\n",
    "# create the weight column for each ticker, weight = 1 / total num of ticker in the rebalance date\n",
    "df_dividend_select_yield['weight'] = 1 / df_dividend_select_yield.groupby('rebalance_date')['ticker'].transform('count')\n",
    "\n",
    "df_weight = pd.pivot(df_dividend_select_yield, index='rebalance_date', columns='ticker', values='weight').copy()\n",
    "df_weight.fillna(0,inplace=True)\n",
    "\n",
    "# calculate the turnover by calculate the abs change of weight and sum up\n",
    "df_weight_change = df_weight.diff().abs() / 2 * 100\n",
    "df_quarterly_turnover = df_weight_change.sum(axis=1).reset_index()\n",
    "df_quarterly_turnover.columns = ['rebalance_date','turnover']\n",
    "\n",
    "df_quarterly_turnover['year'] = df_quarterly_turnover['rebalance_date'].dt.year\n",
    "df_quarterly_turnover['quarter'] = df_quarterly_turnover['rebalance_date'].dt.quarter\n",
    "df_yearly_turnover = (df_quarterly_turnover.groupby('year')['turnover'].mean() * 4).reset_index()\n",
    "# df_yearly_turnover = df_quarterly_turnover.groupby('quarter')['turnover'].mean().reset_index()\n",
    "df_yearly_turnover['turnover'].describe().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>85.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>87.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>92.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>115.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>90.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010</td>\n",
       "      <td>95.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011</td>\n",
       "      <td>130.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>95.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014</td>\n",
       "      <td>97.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015</td>\n",
       "      <td>92.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>105.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>90.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018</td>\n",
       "      <td>97.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021</td>\n",
       "      <td>87.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022</td>\n",
       "      <td>85.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  turnover\n",
       "0   2005   85.0000\n",
       "1   2006   87.5000\n",
       "2   2007   92.5000\n",
       "3   2008  115.0000\n",
       "4   2009   90.0000\n",
       "5   2010   95.0000\n",
       "6   2011  130.0000\n",
       "7   2012  100.0000\n",
       "8   2013   95.0000\n",
       "9   2014   97.5000\n",
       "10  2015   92.5000\n",
       "11  2016  105.0000\n",
       "12  2017   90.0000\n",
       "13  2018   97.5000\n",
       "14  2019   80.0000\n",
       "15  2020   80.0000\n",
       "16  2021   87.5000\n",
       "17  2022   85.0000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yearly_turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df_quarterly_turnover[['date','turnover']].plot(kind='bar', x='date', y='turnover', figsize=(20, 10))\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Capabilities for Market Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1235.0000\n",
       "mean     813590.0568\n",
       "std      451041.2033\n",
       "min      134186.1269\n",
       "25%      517625.6721\n",
       "50%      701145.5324\n",
       "75%      991915.4138\n",
       "max     4037307.1490\n",
       "Name: amount_assumption, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal_day = df_portfolio_value_detail_all[df_portfolio_value_detail_all['date'].isin(reb_lst) == False].sort_values(['date','ticker']).reset_index(drop = True).copy()\n",
    "df_normal_day = df_normal_day[df_normal_day['date'] > '2018-01-01']\n",
    "# Compute the total value for each date\n",
    "total_value = df_normal_day.groupby('date')['value'].transform('sum')\n",
    "\n",
    "# Compute the weight of each ticker by dividing its value by the total value for its date\n",
    "df_normal_day['weight'] = df_normal_day['value'] / total_value\n",
    "df_amount = df_price[['日期','股票代號','成交金額(千)']]\n",
    "df_amount.columns = ['date','ticker','amount']\n",
    "\n",
    "df_normal_day = pd.merge(df_normal_day, df_amount, how='left', on=['date', 'ticker']).dropna().reset_index(drop = True)\n",
    "df_normal_day['amount'] = df_normal_day['amount'].astype(int)\n",
    "df_normal_day = df_normal_day[df_normal_day['amount'] != 0]\n",
    "df_normal_day['amount_assumption'] = df_normal_day['amount'] * 0.5 / df_normal_day['weight']\n",
    "df_normal_day.sort_values(['date','amount_assumption'], inplace=True)\n",
    "df_normal_day = df_normal_day.merge(df_factor_all_amount_rank[['date','ticker','amount_rank_20']], how='left', on=['date','ticker'])\n",
    "df_normal_day.groupby('date')['amount_assumption'].min().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Portfolio Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmarks.plot(y = ['TWA02_scale','portfolio_value_scale'], label = ['Benchmark','國泰中小'], figsize = (10, 5), title = 'Benchmark vs Portfolio', color = ['gray',\"green\"])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Yearly Win Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmarks_all = pd.read_excel('./data/benchmarks.xlsx')\n",
    "df_benchmarks_all.columns = ['日期', 'TWA02', 'TWA00']\n",
    "benchmark_list = df_benchmarks_all.columns.to_list()\n",
    "benchmark_list.remove('日期')\n",
    "\n",
    "index_name = benchmark_list[0]\n",
    "df_benchmarks_temp = df_benchmarks_all[['日期',f'{index_name}']].copy()\n",
    "df_benchmarks_temp.columns = ['date',f'{index_name}']\n",
    "df_benchmarks_temp.dropna(inplace=True)\n",
    "# change the date format to datetime\n",
    "df_benchmarks_temp['date'] = pd.to_datetime(df_benchmarks_temp['date'], format='%Y/%m/%d')\n",
    "df_benchmarks_temp.sort_values('date', inplace=True)\n",
    "df_benchmarks = df_benchmarks_temp.merge(df_compare_portfolio, on='date', how='left').dropna().copy()\n",
    "df_benchmarks.reset_index(drop=True, inplace=True)\n",
    "df_benchmarks.drop_duplicates(inplace=True)\n",
    "\n",
    "# df_benchmarks = df_benchmarks[df_benchmarks['date']> '2018-08-01']\n",
    "# scale the benchmark and portfolio value to 1\n",
    "df_benchmarks[f'{index_name}_scale'] = df_benchmarks[f'{index_name}'] / df_benchmarks[f'{index_name}'].iloc[0]\n",
    "df_benchmarks['portfolio_value_scale'] = df_benchmarks['portfolio_value'] / df_benchmarks['portfolio_value'].iloc[0]\n",
    "\n",
    "df_benchmarks.set_index('date', inplace=True)\n",
    "\n",
    "df_benchmarks['portfolio_value_rt'] = df_benchmarks['portfolio_value_scale'].pct_change()\n",
    "df_benchmarks[f'{index_name}_rt'] = df_benchmarks[f'{index_name}_scale'].pct_change()\n",
    "\n",
    "# calculate the beta of portfolio and benchmark\n",
    "beta = df_benchmarks[['portfolio_value_rt', f'{index_name}_rt']].cov().iloc[0,1] / df_benchmarks[f'{index_name}_rt'].var()\n",
    "print(f'beta: {beta:.2f}')\n",
    "\n",
    "# calculate the alpha of portfolio and benchmark\n",
    "alpha = df_benchmarks[['portfolio_value_rt', f'{index_name}_rt']].mean().iloc[0] - beta * df_benchmarks[f'{index_name}_rt'].mean()\n",
    "# annualized the alpha\n",
    "ann_alpha = (1 + alpha) ** 252 - 1\n",
    "print(f'alpha TR: {ann_alpha:.2%}')\n",
    "\n",
    "df_benchmarks['year'] = df_benchmarks.index.year\n",
    "df_benchmarks['month'] = df_benchmarks.index.month\n",
    "df_benchmarks['quarter'] = df_benchmarks.index.quarter\n",
    "\n",
    "last_values = df_benchmarks.groupby(['year','month']).tail(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "first_values  = df_benchmarks.groupby(['year','month']).head(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "\n",
    "last_values = df_benchmarks.groupby(['year']).tail(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "first_values  = df_benchmarks.groupby(['year']).head(1)[[f'{index_name}','portfolio_value_scale']].values\n",
    "df_yearly_return = pd.DataFrame(last_values / first_values)\n",
    "df_yearly_return.columns = [f'{index_name}','portfolio_value_scale']\n",
    "# drop the last row\n",
    "# df_yearly_return = df_yearly_return[:-1]\n",
    "df_yearly_return['win_rate'] = np.where(df_yearly_return['portfolio_value_scale'] > df_yearly_return[f'{index_name}'], 1, 0)\n",
    "# create a list from 2005 to 2023 for year column for df_yearly_return\n",
    "year_list = list(range(2005,2024))\n",
    "df_yearly_return['year'] = year_list\n",
    "df_yearly_return[['portfolio_value_scale',f'{index_name}']] = df_yearly_return[['portfolio_value_scale',f'{index_name}']] - 1\n",
    "\n",
    "# plot the return of portfolio and benchmark with bar chart\n",
    "df_yearly_return[['portfolio_value_scale',f'{index_name}']].plot.bar(figsize=(12,5), color=['#0faf00ff','#505050ff'])\n",
    "\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "# set font with Arial\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# Set global font to 'Microsoft JhengHei'\n",
    "matplotlib.rcParams['font.family'] = ['Microsoft JhengHei']\n",
    "\n",
    "# set the x axis with column year\n",
    "plt.xticks(df_yearly_return.index, df_yearly_return['year'])\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# rotate the x axis 45 degree\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# format the yticks with % without other module\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "plt.legend(['國泰投信中小高股息指數', '加權指報酬指數'])\n",
    "plt.grid()\n",
    "# plt.savefig(f'./figs/{model_folder_name}/{file_name_prefix}_ann_return.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quarterly_div.groupby('year')['weighted_yield'].sum().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Yearly Dividends Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quarterly_div.groupby('year')['weighted_yield'].sum().plot(kind='bar', figsize=(10, 5))\n",
    "plt.title('Dividends Yield by Year')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_trading_window(trading_days, quarterly_dates, direction='both'):\n",
    "    \"\"\"\n",
    "    Get 5 trading days before and/or after each date in quarterly_dates that exists in trading_days.\n",
    "\n",
    "    Parameters:\n",
    "    - trading_days (list): List of trading dates\n",
    "    - quarterly_dates (list): List of quarterly dates\n",
    "    - direction (str): 'before', 'after', or 'both' (default is 'both')\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary where key is the date from quarterly_dates and value is a list of 5 trading days before and/or after.\n",
    "    \"\"\"\n",
    "    \n",
    "    # result = {}\n",
    "    result = []\n",
    "    \n",
    "    for q_date in quarterly_dates:\n",
    "        if q_date in trading_days:\n",
    "            index = trading_days.index(q_date)\n",
    "            \n",
    "            before_window = trading_days[max(0, index-5):index] if index >= 5 else trading_days[0:index]\n",
    "            after_window = trading_days[index+1:index+6] if index+6 <= len(trading_days) else trading_days[index+1:]\n",
    "            \n",
    "            if direction == 'before':\n",
    "                # result[q_date] = before_window\n",
    "                result.append(before_window)\n",
    "\n",
    "            elif direction == 'after':\n",
    "                # result[q_date] = after_window\n",
    "                result.append(after_window)\n",
    "            else:\n",
    "                # result[q_date] = (before_window, after_window)\n",
    "                result.append(before_window)\n",
    "                result.append(after_window)\n",
    "                # result[q_date] = (before_window, after_window)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_before_reb = get_trading_window(df_portfolio_value_detail_all['date'].unique().tolist(), reb_lst, 'before')\n",
    "# flatten the list\n",
    "date_before_reb = [item for sublist in date_before_reb for item in sublist]\n",
    "\n",
    "df_rebalance_days_before = df_portfolio_value_detail_all[df_portfolio_value_detail_all['date'].isin(date_before_reb)].sort_values(['date','ticker']).reset_index(drop = True).copy()\n",
    "df_rebalance_days_before = df_rebalance_days_before[df_rebalance_days_before['date'] > '2018-01-01']\n",
    "# Compute the total value for each date\n",
    "total_value = df_rebalance_days_before.groupby('date')['value'].transform('sum')\n",
    "\n",
    "# Compute the weight of each ticker by dividing its value by the total value fJor its date\n",
    "df_rebalance_days_before['weight'] = df_rebalance_days_before['value'] / total_value\n",
    "df_amount = df_price[['日期','股票代號','成交金額(千)']]\n",
    "df_amount.columns = ['date','ticker','amount']\n",
    "\n",
    "df_rebalance_days_before = pd.merge(df_rebalance_days_before, df_amount, how='left', on=['date', 'ticker']).dropna().reset_index(drop = True)\n",
    "df_rebalance_days_before['amount'] = df_rebalance_days_before['amount'].astype(int)\n",
    "df_rebalance_days_before = df_rebalance_days_before[df_rebalance_days_before['amount'] != 0]\n",
    "\n",
    "df_rebalance_days_before['reb_amount'] = 20000000 * df_rebalance_days_before['weight'] / 5\n",
    "df_rebalance_days_before['ratio_assumption'] = df_rebalance_days_before['reb_amount'] / df_rebalance_days_before['amount'] \n",
    "df_rebalance_days_before.sort_values(['date','ratio_assumption'], inplace=True)\n",
    "\n",
    "df_rebalance_days_before.groupby('date')['ratio_assumption'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_after_reb = get_trading_window(df_portfolio_value_detail_all['date'].unique().tolist(), reb_lst, 'after')\n",
    "# flatten the list\n",
    "date_after_reb = [item for sublist in date_after_reb for item in sublist]\n",
    "\n",
    "df_rebalance_days_after = df_portfolio_value_detail_all[df_portfolio_value_detail_all['date'].isin(date_after_reb)].sort_values(['date','ticker']).reset_index(drop = True).copy()\n",
    "df_rebalance_days_after = df_rebalance_days_after[df_rebalance_days_after['date'] > '2018-01-01']\n",
    "# Compute the total value for each date\n",
    "total_value = df_rebalance_days_after.groupby('date')['value'].transform('sum')\n",
    "\n",
    "# Compute the weight of each ticker by dividing its value by the total value fJor its date\n",
    "df_rebalance_days_after['weight'] = df_rebalance_days_after['value'] / total_value\n",
    "df_amount = df_price[['日期','股票代號','成交金額(千)']]\n",
    "df_amount.columns = ['date','ticker','amount']\n",
    "\n",
    "df_rebalance_days_after = pd.merge(df_rebalance_days_after, df_amount, how='left', on=['date', 'ticker']).dropna().reset_index(drop = True)\n",
    "df_rebalance_days_after['amount'] = df_rebalance_days_after['amount'].astype(int)\n",
    "df_rebalance_days_after = df_rebalance_days_after[df_rebalance_days_after['amount'] != 0]\n",
    "\n",
    "df_rebalance_days_after['reb_amount'] = 40000000 * df_rebalance_days_after['weight'] / 5\n",
    "df_rebalance_days_after['ratio_assumption'] = df_rebalance_days_after['reb_amount'] / df_rebalance_days_after['amount'] \n",
    "df_rebalance_days_after.sort_values(['date','ratio_assumption'], inplace=True)\n",
    "\n",
    "df_rebalance_days_after.groupby('date')['ratio_assumption'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_liq_test = df_factor_all.copy()\n",
    "df_factor_liq_test['market_cap_rank'] = df_factor_liq_test.groupby('date')['market_cap'].rank(ascending=False)\n",
    "df_factor_liq_test = df_factor_liq_test[df_factor_liq_test['market_cap_rank'] <= 50]\n",
    "df_factor_liq_test['weight'] = 0.025\n",
    "df_factor_liq_test = pd.merge(df_factor_liq_test, df_amount, how='left', on=['date', 'ticker']).dropna().reset_index(drop = True)\n",
    "df_factor_liq_test['amount'] = df_factor_liq_test['amount'].astype(int)\n",
    "\n",
    "df_factor_liq_test['reb_amount'] = 40000000 * df_factor_liq_test['weight'] / 5\n",
    "df_factor_liq_test['ratio_assumption'] = df_factor_liq_test['reb_amount'] / df_factor_liq_test['amount'] \n",
    "df_factor_liq_test.sort_values(['date','ratio_assumption'], inplace=True)\n",
    "df_factor_liq_test = df_factor_liq_test[['date','ticker','ratio_assumption']]\n",
    "df_factor_liq_test = df_factor_liq_test[df_factor_liq_test['date'] >= '2018-01-01']\n",
    "# df_factor_liq_test = df_factor_liq_test.merge(df_price_sub[['date','ticker','20_d_mean_amount_k','252_d_mean_amount_k']], on = ['date','ticker'], how = 'left')\n",
    "df_factor_liq_test.groupby('date')['ratio_assumption'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00929_holdings = pd.read_excel('./data/00929.xlsx')\n",
    "df_00929_holdings['日期'] = pd.to_datetime(df_00929_holdings['日期'])\n",
    "# format 日期 to yyyymmdd as string\n",
    "df_00929_holdings['日期'] = df_00929_holdings['日期'].dt.strftime('%Y%m%d')\n",
    "df_00929_holdings = df_00929_holdings[['日期','標的代號','權重(%)']]\n",
    "df_00929_holdings['標的代號'] = df_00929_holdings['標的代號'].astype(str)\n",
    "df_00929_holdings = pd.merge(df_00929_holdings,df_new_price, left_on=['日期','標的代號'], right_on=['日期','股票代號'], how = 'left').dropna()\n",
    "df_00929_holdings = df_00929_holdings[['日期','標的代號','成交金額(千)','權重(%)']]\n",
    "df_00929_holdings['權重(%)'] = df_00929_holdings['權重(%)'] / 100\n",
    "df_00929_holdings['amount_assumption'] = df_00929_holdings['成交金額(千)'] * 0.25 / df_00929_holdings['權重(%)']\n",
    "df_00929_holdings['ratio_assumption'] = 40000000 * df_00929_holdings['權重(%)'] / 5 / df_00929_holdings['成交金額(千)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00929_holdings['ratio_assumption'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_00929_holdings.groupby('日期')['amount_assumption'].min().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all.to_feather(f'./data/model/{model_folder_name}/df_factor_all_select.feather')\n",
    "df_factor_all_test = df_factor_all.copy()\n",
    "df_factor_all_test.sort_values(['date','ticker'], inplace=True)\n",
    "df_factor_all_test.reset_index(drop=True, inplace=True)\n",
    "df_factor_all_test['market_cap_billion'] = df_factor_all_test['market_cap'] / 1000000\n",
    "df_factor_all_test['market_cap_rank'] = df_factor_all_test.groupby('date')['market_cap'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change df_factor_all_test date format to yyyymmdd\n",
    "df_factor_all_test['date'] = df_factor_all_test['date'].apply(lambda x: x.strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factor_all_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_market_cap_rank = df_factor_all_test[['date','ticker','market_cap_rank']]\n",
    "df_market_cap_rank = df_market_cap_rank[df_market_cap_rank['date'] == '20230428']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal_day_00929 = df_00929_holdings.merge(df_market_cap_rank, left_on=['標的代號'], right_on=['ticker'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal_day['amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
